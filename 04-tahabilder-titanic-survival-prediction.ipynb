{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction\n",
    "\n",
    "**Author:** Anik Tahabilder  \n",
    "**Project:** 4 of 22 - Kaggle ML Portfolio  \n",
    "**Dataset:** Titanic  \n",
    "**Difficulty:** 3/10 | **Learning Value:** 7/10\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Project?\n",
    "\n",
    "The Titanic dataset is the **\"Hello World\" of machine learning classification**. In Project 1, we explored and understood the data. Now we'll build models to predict survival!\n",
    "\n",
    "### What You'll Learn:\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "| **Data Preprocessing** | Handle missing values, encode categories |\n",
    "| **Feature Engineering** | Create meaningful features from raw data |\n",
    "| **Model Building** | Train multiple classification algorithms |\n",
    "| **Model Evaluation** | Use proper metrics beyond accuracy |\n",
    "| **Model Selection** | Choose the best model for deployment |\n",
    "\n",
    "### The ML Pipeline:\n",
    "\n",
    "```\n",
    "Raw Data → Clean → Engineer Features → Split → Scale → Train → Evaluate → Select Best\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Part 1: Setup and Data Loading](#part1)\n",
    "2. [Part 2: Data Preprocessing](#part2)\n",
    "3. [Part 3: Feature Engineering](#part3)\n",
    "4. [Part 4: Prepare for Modeling](#part4)\n",
    "5. [Part 5: Model Training](#part5)\n",
    "6. [Part 6: Model Evaluation](#part6)\n",
    "7. [Part 7: Feature Importance](#part7)\n",
    "8. [Part 8: Summary and Conclusions](#part8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part1'></a>\n",
    "# Part 1: Setup and Data Loading\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 Import Libraries\n",
    "\n",
    "| Library | Purpose |\n",
    "|---------|--------|\n",
    "| **pandas/numpy** | Data manipulation |\n",
    "| **matplotlib/seaborn** | Visualization |\n",
    "| **sklearn** | Machine learning algorithms and tools |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, classification_report,\n",
    "                             roc_auc_score, roc_curve, precision_recall_curve)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "print(f\"scikit-learn version: {__import__('sklearn').__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TITANIC DATASET LOADED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nShape: {df.shape[0]} passengers, {df.shape[1]} features\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data overview\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA OVERVIEW\")\n",
    "print(\"=\" * 60)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(\"=\" * 60)\n",
    "print(\"MISSING VALUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({'Missing': missing, 'Percent': missing_pct})\n",
    "print(missing_df[missing_df['Missing'] > 0].sort_values('Missing', ascending=False))\n",
    "\n",
    "print(\"\\nKey issues to handle:\")\n",
    "print(\"  - age: 19.87% missing\")\n",
    "print(\"  - deck: 77.22% missing (too much - will drop)\")\n",
    "print(\"  - embarked: 0.22% missing (fill with mode)\")\n",
    "print(\"  - embark_town: 0.22% missing (fill with mode)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part2'></a>\n",
    "# Part 2: Data Preprocessing\n",
    "\n",
    "---\n",
    "\n",
    "## Why Preprocessing Matters\n",
    "\n",
    "Raw data is messy. Machine learning algorithms need clean, structured input.\n",
    "\n",
    "| Issue | Strategy |\n",
    "|-------|----------|\n",
    "| **Missing values** | Impute or drop |\n",
    "| **Categorical variables** | Encode to numbers |\n",
    "| **Redundant columns** | Remove |\n",
    "| **Different scales** | Standardize |\n",
    "\n",
    "## 2.1 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean copy\n",
    "data = df.copy()\n",
    "\n",
    "# Strategy 1: Impute Age with median by Pclass and Sex\n",
    "# WHY: Age likely varies by class and gender\n",
    "print(\"Imputing Age...\")\n",
    "data['age'] = data.groupby(['pclass', 'sex'])['age'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "print(f\"  Age missing after imputation: {data['age'].isnull().sum()}\")\n",
    "\n",
    "# Strategy 2: Fill embarked with mode\n",
    "print(\"\\nFilling Embarked...\")\n",
    "data['embarked'] = data['embarked'].fillna(data['embarked'].mode()[0])\n",
    "data['embark_town'] = data['embark_town'].fillna(data['embark_town'].mode()[0])\n",
    "print(f\"  Embarked missing: {data['embarked'].isnull().sum()}\")\n",
    "\n",
    "# Strategy 3: Drop columns with too many missing values or redundant info\n",
    "print(\"\\nDropping columns...\")\n",
    "columns_to_drop = ['deck', 'alive', 'who', 'adult_male', 'class', 'embark_town']\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "print(f\"  Dropped: {columns_to_drop}\")\n",
    "print(f\"  Remaining columns: {list(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify no missing values remain\n",
    "print(\"=\" * 60)\n",
    "print(\"MISSING VALUES CHECK\")\n",
    "print(\"=\" * 60)\n",
    "print(data.isnull().sum())\n",
    "print(f\"\\nTotal missing: {data.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Encode Categorical Variables\n",
    "\n",
    "ML algorithms need numbers, not strings!\n",
    "\n",
    "| Encoding Method | When to Use |\n",
    "|-----------------|-------------|\n",
    "| **Label Encoding** | Ordinal categories (Low/Medium/High) |\n",
    "| **One-Hot Encoding** | Nominal categories (no order) |\n",
    "| **Binary Encoding** | Two categories |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check categorical columns\n",
    "print(\"Categorical columns:\")\n",
    "for col in data.select_dtypes(include=['object', 'category']).columns:\n",
    "    print(f\"  {col}: {data[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "print(\"=\" * 60)\n",
    "print(\"ENCODING CATEGORICAL VARIABLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Binary encoding for sex\n",
    "data['sex'] = data['sex'].map({'male': 0, 'female': 1})\n",
    "print(\"sex: male=0, female=1\")\n",
    "\n",
    "# One-hot encoding for embarked\n",
    "data = pd.get_dummies(data, columns=['embarked'], prefix='embarked', drop_first=True)\n",
    "print(\"embarked: One-hot encoded (dropped first category)\")\n",
    "\n",
    "# Convert boolean to int\n",
    "data['alone'] = data['alone'].astype(int)\n",
    "print(\"alone: Converted to 0/1\")\n",
    "\n",
    "print(f\"\\nFinal columns: {list(data.columns)}\")\n",
    "print(f\"Shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the cleaned data\n",
    "print(\"Cleaned Data Sample:\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part3'></a>\n",
    "# Part 3: Feature Engineering\n",
    "\n",
    "---\n",
    "\n",
    "## What is Feature Engineering?\n",
    "\n",
    "Creating new features from existing data to help the model learn better patterns.\n",
    "\n",
    "> \"Feature engineering is the art of extracting more information from existing data.\"\n",
    "\n",
    "### Ideas for Titanic:\n",
    "- **Family size** = SibSp + Parch + 1\n",
    "- **Is alone** = Family size == 1\n",
    "- **Title** extracted from name\n",
    "- **Age groups** (bins)\n",
    "- **Fare per person**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Family Size\n",
    "data['family_size'] = data['sibsp'] + data['parch'] + 1\n",
    "print(\"\\n1. Created 'family_size' = sibsp + parch + 1\")\n",
    "print(f\"   Range: {data['family_size'].min()} - {data['family_size'].max()}\")\n",
    "\n",
    "# 2. Is Small Family (optimal for survival based on EDA)\n",
    "data['is_small_family'] = ((data['family_size'] >= 2) & (data['family_size'] <= 4)).astype(int)\n",
    "print(\"\\n2. Created 'is_small_family' (family size 2-4)\")\n",
    "\n",
    "# 3. Age Groups\n",
    "data['age_group'] = pd.cut(data['age'], \n",
    "                           bins=[0, 12, 18, 35, 60, 100],\n",
    "                           labels=[0, 1, 2, 3, 4])  # Child, Teen, Adult, Middle, Senior\n",
    "data['age_group'] = data['age_group'].astype(int)\n",
    "print(\"\\n3. Created 'age_group' (0=Child, 1=Teen, 2=Adult, 3=Middle, 4=Senior)\")\n",
    "\n",
    "# 4. Fare per person\n",
    "data['fare_per_person'] = data['fare'] / data['family_size']\n",
    "print(\"\\n4. Created 'fare_per_person' = fare / family_size\")\n",
    "\n",
    "# 5. Is Child\n",
    "data['is_child'] = (data['age'] < 12).astype(int)\n",
    "print(\"\\n5. Created 'is_child' (age < 12)\")\n",
    "\n",
    "print(f\"\\nFinal feature count: {data.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View engineered features\n",
    "print(\"Data with Engineered Features:\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize engineered features vs survival\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Family Size\n",
    "survival_by_family = data.groupby('family_size')['survived'].mean()\n",
    "axes[0, 0].bar(survival_by_family.index, survival_by_family.values, color='steelblue', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Family Size')\n",
    "axes[0, 0].set_ylabel('Survival Rate')\n",
    "axes[0, 0].set_title('Survival Rate by Family Size', fontweight='bold')\n",
    "axes[0, 0].axhline(y=data['survived'].mean(), color='red', linestyle='--', label='Overall Rate')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Age Group\n",
    "survival_by_age = data.groupby('age_group')['survived'].mean()\n",
    "labels = ['Child', 'Teen', 'Adult', 'Middle', 'Senior']\n",
    "axes[0, 1].bar(range(len(survival_by_age)), survival_by_age.values, color='darkorange', edgecolor='black')\n",
    "axes[0, 1].set_xticks(range(len(labels)))\n",
    "axes[0, 1].set_xticklabels(labels)\n",
    "axes[0, 1].set_xlabel('Age Group')\n",
    "axes[0, 1].set_ylabel('Survival Rate')\n",
    "axes[0, 1].set_title('Survival Rate by Age Group', fontweight='bold')\n",
    "axes[0, 1].axhline(y=data['survived'].mean(), color='red', linestyle='--')\n",
    "\n",
    "# 3. Is Small Family\n",
    "survival_by_small = data.groupby('is_small_family')['survived'].mean()\n",
    "axes[1, 0].bar(['Large/Alone', 'Small (2-4)'], survival_by_small.values, \n",
    "               color=['crimson', 'forestgreen'], edgecolor='black')\n",
    "axes[1, 0].set_ylabel('Survival Rate')\n",
    "axes[1, 0].set_title('Survival Rate: Small Family Advantage', fontweight='bold')\n",
    "\n",
    "# 4. Is Child\n",
    "survival_by_child = data.groupby('is_child')['survived'].mean()\n",
    "axes[1, 1].bar(['Adult', 'Child'], survival_by_child.values,\n",
    "               color=['steelblue', 'gold'], edgecolor='black')\n",
    "axes[1, 1].set_ylabel('Survival Rate')\n",
    "axes[1, 1].set_title('Survival Rate: Children vs Adults', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"- Small families (2-4) had the highest survival rates\")\n",
    "print(\"- Children had better survival rates than adults\")\n",
    "print(\"- Being alone or in very large family reduced survival chances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part4'></a>\n",
    "# Part 4: Prepare for Modeling\n",
    "\n",
    "---\n",
    "\n",
    "## 4.1 Define Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE SELECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# All columns except 'survived'\n",
    "feature_cols = [col for col in data.columns if col != 'survived']\n",
    "\n",
    "X = data[feature_cols]\n",
    "y = data['survived']\n",
    "\n",
    "print(f\"\\nFeatures ({len(feature_cols)}): {feature_cols}\")\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nSurvival rate: {y.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Maintain class proportions\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTraining set: {len(X_train)} samples ({len(X_train)/len(X)*100:.0f}%)\")\n",
    "print(f\"Testing set: {len(X_test)} samples ({len(X_test)/len(X)*100:.0f}%)\")\n",
    "print(f\"\\nTraining survival rate: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"Testing survival rate: {y_test.mean()*100:.2f}%\")\n",
    "print(\"\\nStratification maintained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Feature Scaling\n",
    "\n",
    "Some algorithms are sensitive to feature scales:\n",
    "\n",
    "| Needs Scaling | Doesn't Need Scaling |\n",
    "|---------------|---------------------|\n",
    "| Logistic Regression | Decision Tree |\n",
    "| KNN | Random Forest |\n",
    "| SVM | Gradient Boosting |\n",
    "| Neural Networks | Naive Bayes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data only, transform both\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE SCALING\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nBefore scaling (first 3 features):\")\n",
    "print(f\"  Mean: {X_train.iloc[:, :3].mean().values.round(2)}\")\n",
    "print(f\"  Std:  {X_train.iloc[:, :3].std().values.round(2)}\")\n",
    "\n",
    "print(\"\\nAfter scaling (first 3 features):\")\n",
    "print(f\"  Mean: {X_train_scaled[:, :3].mean(axis=0).round(4)}\")\n",
    "print(f\"  Std:  {X_train_scaled[:, :3].std(axis=0).round(4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part5'></a>\n",
    "# Part 5: Model Training\n",
    "\n",
    "---\n",
    "\n",
    "## Classification Algorithms\n",
    "\n",
    "| Algorithm | Type | Strength |\n",
    "|-----------|------|----------|\n",
    "| **Logistic Regression** | Linear | Simple, interpretable |\n",
    "| **KNN** | Instance-based | No assumptions about data |\n",
    "| **Decision Tree** | Tree-based | Easy to understand |\n",
    "| **Random Forest** | Ensemble | Robust, handles overfitting |\n",
    "| **Gradient Boosting** | Ensemble | High accuracy |\n",
    "| **SVM** | Kernel-based | Effective in high dimensions |\n",
    "| **Naive Bayes** | Probabilistic | Fast, works with small data |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=5),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "print(\"Models to train:\")\n",
    "for i, name in enumerate(models.keys(), 1):\n",
    "    print(f\"  {i}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models and collect results\n",
    "results = {}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TRAINING MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Use scaled data for distance/gradient-based algorithms\n",
    "    if name in ['Logistic Regression', 'K-Nearest Neighbors', 'SVM']:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba,\n",
    "        'accuracy': accuracy,\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"  ROC-AUC:  {roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part6'></a>\n",
    "# Part 6: Model Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "## 6.1 Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [r['accuracy'] for r in results.values()],\n",
    "    'ROC-AUC': [r['roc_auc'] for r in results.values()]\n",
    "}).sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "comparison['Rank'] = range(1, len(comparison) + 1)\n",
    "comparison = comparison[['Rank', 'Model', 'Accuracy', 'ROC-AUC']]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Sort by accuracy\n",
    "sorted_results = dict(sorted(results.items(), key=lambda x: x[1]['accuracy'], reverse=True))\n",
    "names = list(sorted_results.keys())\n",
    "accuracies = [sorted_results[n]['accuracy'] * 100 for n in names]\n",
    "roc_aucs = [sorted_results[n]['roc_auc'] for n in names]\n",
    "\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(names)))\n",
    "\n",
    "# Accuracy\n",
    "bars1 = axes[0].barh(names[::-1], accuracies[::-1], color=colors[::-1], edgecolor='black')\n",
    "axes[0].set_xlim(70, 90)\n",
    "axes[0].set_xlabel('Accuracy (%)')\n",
    "axes[0].set_title('Model Accuracy Comparison', fontweight='bold')\n",
    "for bar, acc in zip(bars1, accuracies[::-1]):\n",
    "    axes[0].text(bar.get_width() + 0.3, bar.get_y() + bar.get_height()/2,\n",
    "                 f'{acc:.1f}%', va='center', fontweight='bold')\n",
    "\n",
    "# ROC-AUC\n",
    "bars2 = axes[1].barh(names[::-1], roc_aucs[::-1], color=colors[::-1], edgecolor='black')\n",
    "axes[1].set_xlim(0.7, 0.95)\n",
    "axes[1].set_xlabel('ROC-AUC Score')\n",
    "axes[1].set_title('Model ROC-AUC Comparison', fontweight='bold')\n",
    "for bar, auc in zip(bars2, roc_aucs[::-1]):\n",
    "    axes[1].text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,\n",
    "                 f'{auc:.3f}', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_model = names[0]\n",
    "print(f\"\\nBest Model: {best_model}\")\n",
    "print(f\"  Accuracy: {sorted_results[best_model]['accuracy']*100:.2f}%\")\n",
    "print(f\"  ROC-AUC: {sorted_results[best_model]['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Cross-Validation\n",
    "\n",
    "A single train-test split might not be reliable. Cross-validation gives a more robust estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold Cross-Validation\n",
    "print(\"=\" * 70)\n",
    "print(\"5-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "cv_results = {}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Use appropriate data\n",
    "    if name in ['Logistic Regression', 'K-Nearest Neighbors', 'SVM']:\n",
    "        X_cv = scaler.fit_transform(X)\n",
    "    else:\n",
    "        X_cv = X\n",
    "    \n",
    "    scores = cross_val_score(model, X_cv, y, cv=cv, scoring='accuracy')\n",
    "    cv_results[name] = {\n",
    "        'mean': scores.mean(),\n",
    "        'std': scores.std(),\n",
    "        'scores': scores\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Scores: {scores.round(4)}\")\n",
    "    print(f\"  Mean: {scores.mean():.4f} (+/- {scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CV results\n",
    "cv_sorted = dict(sorted(cv_results.items(), key=lambda x: x[1]['mean'], reverse=True))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "names_cv = list(cv_sorted.keys())\n",
    "means = [cv_sorted[n]['mean'] * 100 for n in names_cv]\n",
    "stds = [cv_sorted[n]['std'] * 100 for n in names_cv]\n",
    "\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(names_cv)))\n",
    "bars = ax.barh(names_cv[::-1], means[::-1], xerr=stds[::-1],\n",
    "               color=colors[::-1], edgecolor='black', capsize=5)\n",
    "\n",
    "ax.set_xlim(70, 90)\n",
    "ax.set_xlabel('Cross-Validation Accuracy (%)')\n",
    "ax.set_title('5-Fold Cross-Validation Results', fontweight='bold')\n",
    "\n",
    "for bar, mean, std in zip(bars, means[::-1], stds[::-1]):\n",
    "    ax.text(bar.get_width() + std + 0.5, bar.get_y() + bar.get_height()/2,\n",
    "            f'{mean:.1f}%', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_cv = names_cv[0]\n",
    "print(f\"\\nBest Model (CV): {best_cv}\")\n",
    "print(f\"  Mean Accuracy: {cv_sorted[best_cv]['mean']*100:.2f}%\")\n",
    "print(f\"  Std: +/- {cv_sorted[best_cv]['std']*200:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices for top 4 models\n",
    "top_models = list(sorted_results.keys())[:4]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, name in enumerate(top_models):\n",
    "    cm = confusion_matrix(y_test, results[name]['predictions'])\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                xticklabels=['Died', 'Survived'], yticklabels=['Died', 'Survived'],\n",
    "                annot_kws={'size': 14, 'weight': 'bold'})\n",
    "    axes[i].set_title(f'{name}\\nAccuracy: {results[name][\"accuracy\"]*100:.1f}%', fontweight='bold')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    axes[i].set_ylabel('Actual')\n",
    "\n",
    "plt.suptitle('Confusion Matrices - Top 4 Models', fontweight='bold', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Reading Confusion Matrix:\")\n",
    "print(\"  - Top-left (TN): Correctly predicted death\")\n",
    "print(\"  - Top-right (FP): Predicted survival but died\")\n",
    "print(\"  - Bottom-left (FN): Predicted death but survived\")\n",
    "print(\"  - Bottom-right (TP): Correctly predicted survival\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(results)))\n",
    "\n",
    "for (name, res), color in zip(results.items(), colors):\n",
    "    fpr, tpr, _ = roc_curve(y_test, res['probabilities'])\n",
    "    ax.plot(fpr, tpr, color=color, linewidth=2,\n",
    "            label=f\"{name} (AUC = {res['roc_auc']:.3f})\")\n",
    "\n",
    "# Diagonal line (random classifier)\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curves - All Models', fontweight='bold', fontsize=14)\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1.05])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nROC Curve Interpretation:\")\n",
    "print(\"  - Curve closer to top-left = better model\")\n",
    "print(\"  - AUC (Area Under Curve) closer to 1.0 = better discrimination\")\n",
    "print(\"  - AUC = 0.5 means random guessing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Classification Report for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "best_model_name = list(sorted_results.keys())[0]\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"CLASSIFICATION REPORT: {best_model_name}\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(y_test, best_predictions, target_names=['Died', 'Survived']))\n",
    "\n",
    "print(\"\\nMetric Definitions:\")\n",
    "print(\"  - Precision: Of predicted survivors, how many actually survived?\")\n",
    "print(\"  - Recall: Of actual survivors, how many did we identify?\")\n",
    "print(\"  - F1-Score: Balance between precision and recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part7'></a>\n",
    "# Part 7: Feature Importance\n",
    "\n",
    "---\n",
    "\n",
    "Which features matter most for predicting survival?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest\n",
    "rf_model = results['Random Forest']['model']\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FEATURE IMPORTANCE (Random Forest)\")\n",
    "print(\"=\" * 60)\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(feature_importance)))\n",
    "bars = ax.barh(feature_importance['Feature'][::-1], \n",
    "               feature_importance['Importance'][::-1] * 100,\n",
    "               color=colors[::-1], edgecolor='black')\n",
    "\n",
    "ax.set_xlabel('Importance (%)', fontsize=12)\n",
    "ax.set_title('Feature Importance for Survival Prediction', fontweight='bold', fontsize=14)\n",
    "\n",
    "for bar, imp in zip(bars, feature_importance['Importance'][::-1]):\n",
    "    ax.text(bar.get_width() + 0.3, bar.get_y() + bar.get_height()/2,\n",
    "            f'{imp*100:.1f}%', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "for i, row in feature_importance.head(5).iterrows():\n",
    "    print(f\"  {row['Feature']}: {row['Importance']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature importance across models\n",
    "# Logistic Regression coefficients (absolute value)\n",
    "lr_model = results['Logistic Regression']['model']\n",
    "lr_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Coefficient': np.abs(lr_model.coef_[0])\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Random Forest\n",
    "axes[0].barh(feature_importance['Feature'][::-1], \n",
    "             feature_importance['Importance'][::-1] * 100,\n",
    "             color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Importance (%)')\n",
    "axes[0].set_title('Random Forest Feature Importance', fontweight='bold')\n",
    "\n",
    "# Logistic Regression\n",
    "axes[1].barh(lr_importance['Feature'][::-1], \n",
    "             lr_importance['Coefficient'][::-1],\n",
    "             color='darkorange', edgecolor='black')\n",
    "axes[1].set_xlabel('|Coefficient|')\n",
    "axes[1].set_title('Logistic Regression Coefficients', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Both models agree: sex and fare are among the most important features!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part8'></a>\n",
    "# Part 8: Summary and Conclusions\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary visualization\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Model Comparison (accuracy)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "models_sorted = list(sorted_results.keys())\n",
    "acc_sorted = [sorted_results[m]['accuracy']*100 for m in models_sorted]\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(models_sorted)))\n",
    "bars = ax1.bar(models_sorted, acc_sorted, color=colors, edgecolor='black')\n",
    "ax1.set_ylim(70, 90)\n",
    "ax1.set_ylabel('Accuracy (%)')\n",
    "ax1.set_title('Model Accuracy Comparison', fontweight='bold', fontsize=14)\n",
    "for bar, acc in zip(bars, acc_sorted):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3,\n",
    "             f'{acc:.1f}%', ha='center', fontweight='bold')\n",
    "ax1.tick_params(axis='x', rotation=15)\n",
    "\n",
    "# 2. Feature Importance\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "top_features = feature_importance.head(6)\n",
    "ax2.barh(top_features['Feature'][::-1], \n",
    "         top_features['Importance'][::-1] * 100,\n",
    "         color=plt.cm.viridis(np.linspace(0.3, 0.9, 6))[::-1], edgecolor='black')\n",
    "ax2.set_xlabel('Importance (%)')\n",
    "ax2.set_title('Top Features', fontweight='bold')\n",
    "\n",
    "# 3. Best Model Confusion Matrix\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "best_cm = confusion_matrix(y_test, results[best_model_name]['predictions'])\n",
    "sns.heatmap(best_cm, annot=True, fmt='d', cmap='Blues', ax=ax3,\n",
    "            xticklabels=['Died', 'Survived'], yticklabels=['Died', 'Survived'],\n",
    "            annot_kws={'size': 14, 'weight': 'bold'})\n",
    "ax3.set_title(f'Best Model: {best_model_name}', fontweight='bold')\n",
    "ax3.set_xlabel('Predicted')\n",
    "ax3.set_ylabel('Actual')\n",
    "\n",
    "# 4. Survival Distribution\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "survival_counts = y.value_counts()\n",
    "ax4.pie(survival_counts.values, labels=['Died', 'Survived'], autopct='%1.1f%%',\n",
    "        colors=['#ff6b6b', '#4ecdc4'], explode=(0.02, 0.02), shadow=True,\n",
    "        textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "ax4.set_title('Survival Distribution', fontweight='bold')\n",
    "\n",
    "plt.suptitle('TITANIC SURVIVAL PREDICTION - SUMMARY DASHBOARD', \n",
    "             fontweight='bold', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "### 1. Model Performance\n",
    "- All models achieved **78-83% accuracy**\n",
    "- **Best models**: Gradient Boosting, Random Forest, Logistic Regression\n",
    "- Cross-validation confirms stable performance\n",
    "\n",
    "### 2. Most Important Features\n",
    "| Feature | Importance |\n",
    "|---------|------------|\n",
    "| **Sex** | Highest - Women had much higher survival rates |\n",
    "| **Fare** | Higher fares = higher class = better survival |\n",
    "| **Age** | Children prioritized in evacuation |\n",
    "| **Pclass** | 1st class had better access to lifeboats |\n",
    "\n",
    "### 3. What We Learned\n",
    "\n",
    "| Topic | Key Insight |\n",
    "|-------|-------------|\n",
    "| **Preprocessing** | Handling missing values is crucial |\n",
    "| **Feature Engineering** | Domain knowledge improves predictions |\n",
    "| **Model Selection** | Try multiple algorithms, compare fairly |\n",
    "| **Evaluation** | Use cross-validation, not just accuracy |\n",
    "\n",
    "---\n",
    "\n",
    "## Classification Checklist\n",
    "\n",
    "- [x] Load and explore data\n",
    "- [x] Handle missing values\n",
    "- [x] Encode categorical variables\n",
    "- [x] Engineer new features\n",
    "- [x] Split into train/test\n",
    "- [x] Scale features\n",
    "- [x] Train multiple models\n",
    "- [x] Evaluate with multiple metrics\n",
    "- [x] Cross-validate\n",
    "- [x] Analyze feature importance\n",
    "\n",
    "---\n",
    "\n",
    "**End of Titanic Survival Prediction Tutorial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\"*70)\n",
    "print(\"TITANIC SURVIVAL PREDICTION - FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nDATASET\")\n",
    "print(f\"   Samples: {len(data)}\")\n",
    "print(f\"   Features: {len(feature_cols)}\")\n",
    "print(f\"   Survival rate: {y.mean()*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nBEST MODEL\")\n",
    "print(f\"   Name: {best_model_name}\")\n",
    "print(f\"   Test Accuracy: {results[best_model_name]['accuracy']*100:.2f}%\")\n",
    "print(f\"   ROC-AUC: {results[best_model_name]['roc_auc']:.4f}\")\n",
    "\n",
    "print(f\"\\nALL MODEL ACCURACIES\")\n",
    "for name in sorted_results:\n",
    "    print(f\"   {name}: {sorted_results[name]['accuracy']*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nTOP FEATURES\")\n",
    "for _, row in feature_importance.head(5).iterrows():\n",
    "    print(f\"   {row['Feature']}: {row['Importance']*100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREDICTION COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
