{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Generation with GANs - Complete Tutorial\n",
    "\n",
    "**Author:** Anik Tahabilder  \n",
    "**Project:** 16 of 22 - Kaggle ML Portfolio  \n",
    "**Difficulty:** 9/10 | **Learning Value:** 9/10\n",
    "\n",
    "---\n",
    "\n",
    "## What Will You Learn?\n",
    "\n",
    "This tutorial builds **Generative Adversarial Networks** from scratch, progressing from simple to advanced:\n",
    "\n",
    "| Part | Model | Output Quality |\n",
    "|------|-------|----------------|\n",
    "| 1 | Basic GAN | Blurry digits |\n",
    "| 2 | DCGAN | Clear digits |\n",
    "| 3 | Conditional GAN | Specific digits |\n",
    "| 4 | DCGAN on Fashion | Clothing items |\n",
    "\n",
    "---\n",
    "\n",
    "## GAN Architecture Overview\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                         GAN ARCHITECTURE                                 │\n",
    "├─────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                         │\n",
    "│   ┌─────────────┐      ┌─────────────┐      ┌─────────────┐            │\n",
    "│   │   RANDOM    │      │             │      │  GENERATED  │            │\n",
    "│   │   NOISE     │ ───► │  GENERATOR  │ ───► │   IMAGE     │            │\n",
    "│   │    (z)      │      │    G(z)     │      │   G(z)      │            │\n",
    "│   └─────────────┘      └─────────────┘      └──────┬──────┘            │\n",
    "│                                                     │                   │\n",
    "│                                                     ▼                   │\n",
    "│                                            ┌───────────────┐            │\n",
    "│   ┌─────────────┐                          │               │            │\n",
    "│   │    REAL     │                          │ DISCRIMINATOR │            │\n",
    "│   │   IMAGE     │ ────────────────────────►│               │            │\n",
    "│   │    (x)      │                          │   D(x)        │            │\n",
    "│   └─────────────┘                          └───────┬───────┘            │\n",
    "│                                                     │                   │\n",
    "│                                                     ▼                   │\n",
    "│                                            ┌───────────────┐            │\n",
    "│                                            │  Real or Fake │            │\n",
    "│                                            │   (0 or 1)    │            │\n",
    "│                                            └───────────────┘            │\n",
    "│                                                                         │\n",
    "│   The GENERATOR tries to fool the DISCRIMINATOR                        │\n",
    "│   The DISCRIMINATOR tries to catch fakes                               │\n",
    "│   They compete and both get better!                                    │\n",
    "│                                                                         │\n",
    "└─────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## GAN Training Process\n",
    "\n",
    "```\n",
    "┌─────┐   ┌─────┐   ┌─────┐   ┌─────┐   ┌─────┐   ┌─────┐\n",
    "│  1  │──►│  2  │──►│  3  │──►│  4  │──►│  5  │──►│  6  │\n",
    "└──┬──┘   └──┬──┘   └──┬──┘   └──┬──┘   └──┬──┘   └──┬──┘\n",
    "   │         │         │         │         │         │\n",
    "   ▼         ▼         ▼         ▼         ▼         ▼\n",
    "Define    Select     Train D   Generate  Train D   Train G\n",
    "Problem   Arch.      on Real   Fakes     on Fake   with D\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Part 1: GAN Fundamentals](#part1)\n",
    "2. [Part 2: Basic GAN on MNIST](#part2)\n",
    "3. [Part 3: Deep Convolutional GAN (DCGAN)](#part3)\n",
    "4. [Part 4: Conditional GAN (cGAN)](#part4)\n",
    "5. [Part 5: GAN on Fashion-MNIST](#part5)\n",
    "6. [Part 6: Training Tips & Tricks](#part6)\n",
    "7. [Part 7: Evaluation & Results](#part7)\n",
    "8. [Part 8: Summary](#part8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part1'></a>\n",
    "# Part 1: GAN Fundamentals\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 What is a GAN?\n",
    "\n",
    "**Generative Adversarial Network** = Two neural networks competing:\n",
    "\n",
    "| Network | Role | Analogy |\n",
    "|---------|------|--------|\n",
    "| **Generator (G)** | Creates fake images | Counterfeiter making fake money |\n",
    "| **Discriminator (D)** | Detects fakes | Police detecting counterfeit |\n",
    "\n",
    "## 1.2 The Adversarial Game\n",
    "\n",
    "```\n",
    "Generator's Goal:    Maximize D(G(z)) → Make D think fakes are real\n",
    "Discriminator's Goal: Maximize D(x), Minimize D(G(z)) → Correctly classify\n",
    "```\n",
    "\n",
    "## 1.3 GAN Loss Function\n",
    "\n",
    "**Minimax Game:**\n",
    "```\n",
    "min_G max_D V(D, G) = E[log D(x)] + E[log(1 - D(G(z)))]\n",
    "\n",
    "Where:\n",
    "- D(x) = Discriminator's output for real image x\n",
    "- G(z) = Generator's output for noise z\n",
    "- D(G(z)) = Discriminator's output for fake image\n",
    "```\n",
    "\n",
    "## 1.4 Training Dynamics\n",
    "\n",
    "| Stage | Generator | Discriminator |\n",
    "|-------|-----------|---------------|\n",
    "| Early | Random noise | Easily spots fakes |\n",
    "| Middle | Blurry images | Gets harder to tell |\n",
    "| Late | Realistic images | 50/50 guess (equilibrium) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP AND IMPORTS\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"IMAGE GENERATION WITH GANs - TUTORIAL\")\n",
    "print(\"=\"*70)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(\"\\nAll libraries loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LOAD MNIST DATASET\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING MNIST DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_SIZE = 28\n",
    "CHANNELS = 1\n",
    "LATENT_DIM = 100  # Size of noise vector\n",
    "\n",
    "# Transform: normalize to [-1, 1] for tanh activation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # (x - 0.5) / 0.5 → [-1, 1]\n",
    "])\n",
    "\n",
    "# Load MNIST\n",
    "mnist_train = datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    mnist_train, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(mnist_train):,}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Number of batches: {len(dataloader)}\")\n",
    "print(f\"Image size: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "print(f\"Latent dimension: {LATENT_DIM}\")\n",
    "\n",
    "# Show sample images\n",
    "sample_batch, sample_labels = next(iter(dataloader))\n",
    "print(f\"\\nSample batch shape: {sample_batch.shape}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 8, figsize=(12, 3))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = sample_batch[i].squeeze().numpy()\n",
    "    img = (img + 1) / 2  # Denormalize to [0, 1]\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'{sample_labels[i].item()}')\n",
    "plt.suptitle('Sample MNIST Images', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part2'></a>\n",
    "# Part 2: Basic GAN on MNIST\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 Simple GAN Architecture\n",
    "\n",
    "```\n",
    "GENERATOR:\n",
    "┌────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
    "│ Noise  │──►│ Linear  │──►│ Linear  │──►│ Linear  │──►│  Tanh   │\n",
    "│  100   │   │   256   │   │   512   │   │   784   │   │ [-1,1]  │\n",
    "└────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
    "\n",
    "DISCRIMINATOR:\n",
    "┌────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐   ┌─────────┐\n",
    "│ Image  │──►│ Linear  │──►│ Linear  │──►│ Linear  │──►│ Sigmoid │\n",
    "│  784   │   │   512   │   │   256   │   │    1    │   │  [0,1]  │\n",
    "└────────┘   └─────────┘   └─────────┘   └─────────┘   └─────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BASIC GAN - GENERATOR\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"BASIC GAN ARCHITECTURE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class BasicGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic Generator using fully connected layers.\n",
    "    \n",
    "    Input: Random noise vector (batch, latent_dim)\n",
    "    Output: Generated image (batch, channels, height, width)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=100, img_shape=(1, 28, 28)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_shape = img_shape\n",
    "        img_size = int(np.prod(img_shape))  # 1 * 28 * 28 = 784\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # Layer 1: 100 → 256\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            \n",
    "            # Layer 2: 256 → 512\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            \n",
    "            # Layer 3: 512 → 1024\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            \n",
    "            # Output: 1024 → 784\n",
    "            nn.Linear(1024, img_size),\n",
    "            nn.Tanh()  # Output in [-1, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"Generate images from noise.\"\"\"\n",
    "        img_flat = self.model(z)\n",
    "        img = img_flat.view(img_flat.size(0), *self.img_shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "class BasicDiscriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic Discriminator using fully connected layers.\n",
    "    \n",
    "    Input: Image (batch, channels, height, width)\n",
    "    Output: Probability of being real (batch, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, img_shape=(1, 28, 28)):\n",
    "        super().__init__()\n",
    "        \n",
    "        img_size = int(np.prod(img_shape))  # 784\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # Layer 1: 784 → 512\n",
    "            nn.Linear(img_size, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Layer 2: 512 → 256\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            # Output: 256 → 1\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()  # Output probability [0, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        \"\"\"Classify image as real or fake.\"\"\"\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n",
    "\n",
    "# Create models\n",
    "img_shape = (CHANNELS, IMAGE_SIZE, IMAGE_SIZE)\n",
    "generator = BasicGenerator(LATENT_DIM, img_shape).to(device)\n",
    "discriminator = BasicDiscriminator(img_shape).to(device)\n",
    "\n",
    "print(\"\\nGENERATOR:\")\n",
    "print(generator)\n",
    "\n",
    "print(\"\\nDISCRIMINATOR:\")\n",
    "print(discriminator)\n",
    "\n",
    "# Count parameters\n",
    "g_params = sum(p.numel() for p in generator.parameters())\n",
    "d_params = sum(p.numel() for p in discriminator.parameters())\n",
    "print(f\"\\nGenerator parameters: {g_params:,}\")\n",
    "print(f\"Discriminator parameters: {d_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the models\n",
    "print(\"=\"*70)\n",
    "print(\"TESTING MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Generate random noise\n",
    "test_noise = torch.randn(4, LATENT_DIM, device=device)\n",
    "print(f\"Noise shape: {test_noise.shape}\")\n",
    "\n",
    "# Generate fake images\n",
    "with torch.no_grad():\n",
    "    fake_images = generator(test_noise)\n",
    "print(f\"Generated image shape: {fake_images.shape}\")\n",
    "\n",
    "# Discriminator output\n",
    "with torch.no_grad():\n",
    "    d_output = discriminator(fake_images)\n",
    "print(f\"Discriminator output shape: {d_output.shape}\")\n",
    "print(f\"Discriminator predictions: {d_output.squeeze().cpu().numpy()}\")\n",
    "\n",
    "# Visualize random generator output (before training)\n",
    "fig, axes = plt.subplots(1, 4, figsize=(8, 2))\n",
    "for i, ax in enumerate(axes):\n",
    "    img = fake_images[i].squeeze().cpu().numpy()\n",
    "    img = (img + 1) / 2  # Denormalize\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Generator Output (Before Training) - Random Noise', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAINING BASIC GAN\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING BASIC GAN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def train_basic_gan(generator, discriminator, dataloader, epochs=20, lr=0.0002):\n",
    "    \"\"\"\n",
    "    Train Basic GAN.\n",
    "    \n",
    "    Training Steps:\n",
    "    1. Train Discriminator on real images (label = 1)\n",
    "    2. Train Discriminator on fake images (label = 0)\n",
    "    3. Train Generator (fool discriminator, label = 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Optimizers\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Training history\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    \n",
    "    # Fixed noise for visualization\n",
    "    fixed_noise = torch.randn(64, LATENT_DIM, device=device)\n",
    "    \n",
    "    print(f\"\\nTraining for {epochs} epochs...\")\n",
    "    print(f\"{'Epoch':>6} {'D Loss':>10} {'G Loss':>10} {'D(x)':>8} {'D(G(z))':>10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_g_loss = 0\n",
    "        epoch_d_loss = 0\n",
    "        d_x_total = 0\n",
    "        d_gz_total = 0\n",
    "        \n",
    "        for i, (real_imgs, _) in enumerate(dataloader):\n",
    "            batch_size = real_imgs.size(0)\n",
    "            real_imgs = real_imgs.to(device)\n",
    "            \n",
    "            # Labels\n",
    "            real_labels = torch.ones(batch_size, 1, device=device)\n",
    "            fake_labels = torch.zeros(batch_size, 1, device=device)\n",
    "            \n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            # Loss on real images\n",
    "            d_real = discriminator(real_imgs)\n",
    "            d_real_loss = criterion(d_real, real_labels)\n",
    "            \n",
    "            # Generate fake images\n",
    "            z = torch.randn(batch_size, LATENT_DIM, device=device)\n",
    "            fake_imgs = generator(z)\n",
    "            \n",
    "            # Loss on fake images\n",
    "            d_fake = discriminator(fake_imgs.detach())\n",
    "            d_fake_loss = criterion(d_fake, fake_labels)\n",
    "            \n",
    "            # Total discriminator loss\n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # ---------------------\n",
    "            # Train Generator\n",
    "            # ---------------------\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Generate fake images\n",
    "            z = torch.randn(batch_size, LATENT_DIM, device=device)\n",
    "            fake_imgs = generator(z)\n",
    "            \n",
    "            # Generator wants discriminator to think fakes are real\n",
    "            g_output = discriminator(fake_imgs)\n",
    "            g_loss = criterion(g_output, real_labels)\n",
    "            \n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            # Track metrics\n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            d_x_total += d_real.mean().item()\n",
    "            d_gz_total += d_fake.mean().item()\n",
    "        \n",
    "        # Average losses\n",
    "        n_batches = len(dataloader)\n",
    "        avg_d_loss = epoch_d_loss / n_batches\n",
    "        avg_g_loss = epoch_g_loss / n_batches\n",
    "        avg_d_x = d_x_total / n_batches\n",
    "        avg_d_gz = d_gz_total / n_batches\n",
    "        \n",
    "        g_losses.append(avg_g_loss)\n",
    "        d_losses.append(avg_d_loss)\n",
    "        \n",
    "        print(f\"{epoch+1:>6} {avg_d_loss:>10.4f} {avg_g_loss:>10.4f} {avg_d_x:>8.4f} {avg_d_gz:>10.4f}\")\n",
    "    \n",
    "    return g_losses, d_losses, fixed_noise\n",
    "\n",
    "# Train the GAN\n",
    "g_losses, d_losses, fixed_noise = train_basic_gan(\n",
    "    generator, discriminator, dataloader, epochs=20\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training progress\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Loss curves\n",
    "ax1 = axes[0]\n",
    "ax1.plot(g_losses, label='Generator Loss', color='blue')\n",
    "ax1.plot(d_losses, label='Discriminator Loss', color='red')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Generate final images\n",
    "ax2 = axes[1]\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    fake_imgs = generator(fixed_noise[:16]).cpu()\n",
    "    \n",
    "grid = make_grid(fake_imgs, nrow=4, normalize=True, padding=2)\n",
    "ax2.imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Generated Images (Basic GAN)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part3'></a>\n",
    "# Part 3: Deep Convolutional GAN (DCGAN)\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 Why DCGAN?\n",
    "\n",
    "| Basic GAN | DCGAN |\n",
    "|-----------|-------|\n",
    "| Fully connected layers | Convolutional layers |\n",
    "| Loses spatial information | Preserves spatial structure |\n",
    "| Blurry outputs | Sharper images |\n",
    "| Harder to train | More stable training |\n",
    "\n",
    "## 3.2 DCGAN Architecture Rules\n",
    "\n",
    "1. Replace pooling with strided convolutions (D) and transposed convolutions (G)\n",
    "2. Use BatchNorm in both G and D\n",
    "3. Remove fully connected hidden layers\n",
    "4. Use ReLU in G (except output: Tanh)\n",
    "5. Use LeakyReLU in D\n",
    "\n",
    "```\n",
    "DCGAN GENERATOR:\n",
    "┌────────┐   ┌───────────┐   ┌───────────┐   ┌───────────┐   ┌────────┐\n",
    "│ Noise  │──►│ ConvT 4x4 │──►│ ConvT 4x4 │──►│ ConvT 4x4 │──►│ Image  │\n",
    "│  100   │   │  256 ch   │   │  128 ch   │   │   64 ch   │   │ 28x28  │\n",
    "└────────┘   └───────────┘   └───────────┘   └───────────┘   └────────┘\n",
    "               Upsample       Upsample        Upsample\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DCGAN ARCHITECTURE\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"DCGAN ARCHITECTURE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class DCGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    DCGAN Generator using transposed convolutions.\n",
    "    \n",
    "    Progressively upsamples from noise to image.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=100, channels=1, feature_maps=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.init_size = 7  # Initial size before upsampling\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(latent_dim, feature_maps * 4 * self.init_size * self.init_size)\n",
    "        )\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(feature_maps * 4),\n",
    "            \n",
    "            # Upsample: 7x7 → 14x14\n",
    "            nn.ConvTranspose2d(feature_maps * 4, feature_maps * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_maps * 2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Upsample: 14x14 → 28x28\n",
    "            nn.ConvTranspose2d(feature_maps * 2, feature_maps, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_maps),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # Output: 28x28 → 28x28\n",
    "            nn.Conv2d(feature_maps, channels, 3, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.size(0), -1, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "\n",
    "class DCDiscriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    DCGAN Discriminator using strided convolutions.\n",
    "    \n",
    "    Progressively downsamples image to single probability.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, channels=1, feature_maps=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            # Input: 1x28x28\n",
    "            # Downsample: 28x28 → 14x14\n",
    "            nn.Conv2d(channels, feature_maps, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Downsample: 14x14 → 7x7\n",
    "            nn.Conv2d(feature_maps, feature_maps * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_maps * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Downsample: 7x7 → 3x3\n",
    "            nn.Conv2d(feature_maps * 2, feature_maps * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_maps * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Calculate output size\n",
    "        self.adv_layer = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(feature_maps * 4 * 3 * 3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        features = self.model(img)\n",
    "        validity = self.adv_layer(features)\n",
    "        return validity\n",
    "\n",
    "# Create DCGAN models\n",
    "dc_generator = DCGenerator(LATENT_DIM, CHANNELS).to(device)\n",
    "dc_discriminator = DCDiscriminator(CHANNELS).to(device)\n",
    "\n",
    "# Weight initialization (important for DCGANs)\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "dc_generator.apply(weights_init)\n",
    "dc_discriminator.apply(weights_init)\n",
    "\n",
    "print(\"\\nDCGAN GENERATOR:\")\n",
    "print(dc_generator)\n",
    "\n",
    "print(\"\\nDCGAN DISCRIMINATOR:\")\n",
    "print(dc_discriminator)\n",
    "\n",
    "# Count parameters\n",
    "g_params = sum(p.numel() for p in dc_generator.parameters())\n",
    "d_params = sum(p.numel() for p in dc_discriminator.parameters())\n",
    "print(f\"\\nDCGAN Generator parameters: {g_params:,}\")\n",
    "print(f\"DCGAN Discriminator parameters: {d_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAIN DCGAN\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING DCGAN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def train_dcgan(generator, discriminator, dataloader, epochs=30, lr=0.0002):\n",
    "    \"\"\"\n",
    "    Train DCGAN with improved training strategy.\n",
    "    \"\"\"\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    \n",
    "    fixed_noise = torch.randn(64, LATENT_DIM, device=device)\n",
    "    \n",
    "    # Store generated images at different epochs\n",
    "    image_history = []\n",
    "    \n",
    "    print(f\"\\nTraining DCGAN for {epochs} epochs...\")\n",
    "    print(f\"{'Epoch':>6} {'D Loss':>10} {'G Loss':>10} {'D(x)':>8} {'D(G(z))':>10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_g_loss = 0\n",
    "        epoch_d_loss = 0\n",
    "        d_x_total = 0\n",
    "        d_gz_total = 0\n",
    "        \n",
    "        for i, (real_imgs, _) in enumerate(dataloader):\n",
    "            batch_size = real_imgs.size(0)\n",
    "            real_imgs = real_imgs.to(device)\n",
    "            \n",
    "            # Soft labels for more stable training\n",
    "            real_labels = torch.ones(batch_size, 1, device=device) * 0.9\n",
    "            fake_labels = torch.zeros(batch_size, 1, device=device) + 0.1\n",
    "            \n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            d_real = discriminator(real_imgs)\n",
    "            d_real_loss = criterion(d_real, real_labels)\n",
    "            \n",
    "            z = torch.randn(batch_size, LATENT_DIM, device=device)\n",
    "            fake_imgs = generator(z)\n",
    "            \n",
    "            d_fake = discriminator(fake_imgs.detach())\n",
    "            d_fake_loss = criterion(d_fake, fake_labels)\n",
    "            \n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # ---------------------\n",
    "            # Train Generator\n",
    "            # ---------------------\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            z = torch.randn(batch_size, LATENT_DIM, device=device)\n",
    "            fake_imgs = generator(z)\n",
    "            g_output = discriminator(fake_imgs)\n",
    "            \n",
    "            # Generator wants discriminator output to be 1 (real)\n",
    "            g_loss = criterion(g_output, torch.ones(batch_size, 1, device=device))\n",
    "            \n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            d_x_total += d_real.mean().item()\n",
    "            d_gz_total += d_fake.mean().item()\n",
    "        \n",
    "        n_batches = len(dataloader)\n",
    "        avg_d_loss = epoch_d_loss / n_batches\n",
    "        avg_g_loss = epoch_g_loss / n_batches\n",
    "        avg_d_x = d_x_total / n_batches\n",
    "        avg_d_gz = d_gz_total / n_batches\n",
    "        \n",
    "        g_losses.append(avg_g_loss)\n",
    "        d_losses.append(avg_d_loss)\n",
    "        \n",
    "        # Save generated images periodically\n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            generator.eval()\n",
    "            with torch.no_grad():\n",
    "                gen_imgs = generator(fixed_noise[:16]).cpu()\n",
    "            image_history.append((epoch + 1, gen_imgs))\n",
    "            generator.train()\n",
    "        \n",
    "        print(f\"{epoch+1:>6} {avg_d_loss:>10.4f} {avg_g_loss:>10.4f} {avg_d_x:>8.4f} {avg_d_gz:>10.4f}\")\n",
    "    \n",
    "    return g_losses, d_losses, fixed_noise, image_history\n",
    "\n",
    "# Train DCGAN\n",
    "dc_g_losses, dc_d_losses, dc_fixed_noise, image_history = train_dcgan(\n",
    "    dc_generator, dc_discriminator, dataloader, epochs=30\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training progression\n",
    "print(\"=\"*70)\n",
    "print(\"DCGAN TRAINING PROGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "n_images = len(image_history)\n",
    "fig, axes = plt.subplots(1, n_images, figsize=(4 * n_images, 4))\n",
    "\n",
    "for i, (epoch, imgs) in enumerate(image_history):\n",
    "    grid = make_grid(imgs, nrow=4, normalize=True, padding=2)\n",
    "    axes[i].imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'Epoch {epoch}', fontweight='bold')\n",
    "\n",
    "plt.suptitle('DCGAN Training Progression', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Basic GAN vs DCGAN\n",
    "print(\"=\"*70)\n",
    "print(\"BASIC GAN vs DCGAN COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Basic GAN losses\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(g_losses, label='Generator', color='blue')\n",
    "ax1.plot(d_losses, label='Discriminator', color='red')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Basic GAN Training Loss', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# DCGAN losses\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(dc_g_losses, label='Generator', color='blue')\n",
    "ax2.plot(dc_d_losses, label='Discriminator', color='red')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('DCGAN Training Loss', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Basic GAN outputs\n",
    "ax3 = axes[1, 0]\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    basic_imgs = generator(fixed_noise[:16]).cpu()\n",
    "grid = make_grid(basic_imgs, nrow=4, normalize=True, padding=2)\n",
    "ax3.imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Basic GAN Generated Images', fontweight='bold')\n",
    "\n",
    "# DCGAN outputs\n",
    "ax4 = axes[1, 1]\n",
    "dc_generator.eval()\n",
    "with torch.no_grad():\n",
    "    dc_imgs = dc_generator(dc_fixed_noise[:16]).cpu()\n",
    "grid = make_grid(dc_imgs, nrow=4, normalize=True, padding=2)\n",
    "ax4.imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "ax4.axis('off')\n",
    "ax4.set_title('DCGAN Generated Images', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: DCGAN produces sharper, more recognizable digits!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part4'></a>\n",
    "# Part 4: Conditional GAN (cGAN)\n",
    "\n",
    "---\n",
    "\n",
    "## 4.1 What is Conditional GAN?\n",
    "\n",
    "**Regular GAN:** Generates random images (no control over what digit)\n",
    "\n",
    "**Conditional GAN:** Generates specific images based on a condition (label)\n",
    "\n",
    "```\n",
    "Regular GAN:  noise → Generator → random digit\n",
    "Conditional GAN: noise + label → Generator → specific digit\n",
    "```\n",
    "\n",
    "## 4.2 cGAN Architecture\n",
    "\n",
    "| Component | Input | Output |\n",
    "|-----------|-------|--------|\n",
    "| Generator | noise + label | image of that class |\n",
    "| Discriminator | image + label | real/fake for that class |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONDITIONAL GAN (cGAN)\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"CONDITIONAL GAN (cGAN)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "N_CLASSES = 10  # MNIST has 10 digits\n",
    "\n",
    "class ConditionalGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Conditional Generator - generates images conditioned on class label.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=100, n_classes=10, img_shape=(1, 28, 28)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.img_shape = img_shape\n",
    "        \n",
    "        # Label embedding\n",
    "        self.label_emb = nn.Embedding(n_classes, n_classes)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim + n_classes, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            \n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            \n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, noise, labels):\n",
    "        # Concatenate noise and label embedding\n",
    "        label_input = self.label_emb(labels)\n",
    "        gen_input = torch.cat((noise, label_input), -1)\n",
    "        img = self.model(gen_input)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "class ConditionalDiscriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Conditional Discriminator - classifies images conditioned on class label.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_classes=10, img_shape=(1, 28, 28)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.label_emb = nn.Embedding(n_classes, n_classes)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)) + n_classes, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, labels):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        label_input = self.label_emb(labels)\n",
    "        d_input = torch.cat((img_flat, label_input), -1)\n",
    "        validity = self.model(d_input)\n",
    "        return validity\n",
    "\n",
    "# Create cGAN models\n",
    "cgan_generator = ConditionalGenerator(LATENT_DIM, N_CLASSES, img_shape).to(device)\n",
    "cgan_discriminator = ConditionalDiscriminator(N_CLASSES, img_shape).to(device)\n",
    "\n",
    "print(\"Conditional GAN created!\")\n",
    "print(f\"Generator can generate specific digits (0-9)\")\n",
    "print(f\"Discriminator verifies if image matches the label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAIN CONDITIONAL GAN\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING CONDITIONAL GAN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def train_cgan(generator, discriminator, dataloader, epochs=30, lr=0.0002):\n",
    "    \"\"\"\n",
    "    Train Conditional GAN.\n",
    "    \"\"\"\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    \n",
    "    # Fixed noise and labels for visualization\n",
    "    fixed_noise = torch.randn(100, LATENT_DIM, device=device)\n",
    "    fixed_labels = torch.arange(10, device=device).repeat(10)  # 0,1,2,...,9 repeated 10 times\n",
    "    \n",
    "    print(f\"\\nTraining cGAN for {epochs} epochs...\")\n",
    "    print(f\"{'Epoch':>6} {'D Loss':>10} {'G Loss':>10}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_g_loss = 0\n",
    "        epoch_d_loss = 0\n",
    "        \n",
    "        for i, (real_imgs, labels) in enumerate(dataloader):\n",
    "            batch_size = real_imgs.size(0)\n",
    "            real_imgs = real_imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            real_labels = torch.ones(batch_size, 1, device=device)\n",
    "            fake_labels = torch.zeros(batch_size, 1, device=device)\n",
    "            \n",
    "            # ---------------------\n",
    "            # Train Discriminator\n",
    "            # ---------------------\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            d_real = discriminator(real_imgs, labels)\n",
    "            d_real_loss = criterion(d_real, real_labels)\n",
    "            \n",
    "            z = torch.randn(batch_size, LATENT_DIM, device=device)\n",
    "            gen_labels = torch.randint(0, N_CLASSES, (batch_size,), device=device)\n",
    "            fake_imgs = generator(z, gen_labels)\n",
    "            \n",
    "            d_fake = discriminator(fake_imgs.detach(), gen_labels)\n",
    "            d_fake_loss = criterion(d_fake, fake_labels)\n",
    "            \n",
    "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            # ---------------------\n",
    "            # Train Generator\n",
    "            # ---------------------\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            z = torch.randn(batch_size, LATENT_DIM, device=device)\n",
    "            gen_labels = torch.randint(0, N_CLASSES, (batch_size,), device=device)\n",
    "            fake_imgs = generator(z, gen_labels)\n",
    "            \n",
    "            g_output = discriminator(fake_imgs, gen_labels)\n",
    "            g_loss = criterion(g_output, real_labels)\n",
    "            \n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            epoch_d_loss += d_loss.item()\n",
    "            epoch_g_loss += g_loss.item()\n",
    "        \n",
    "        n_batches = len(dataloader)\n",
    "        g_losses.append(epoch_g_loss / n_batches)\n",
    "        d_losses.append(epoch_d_loss / n_batches)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"{epoch+1:>6} {d_losses[-1]:>10.4f} {g_losses[-1]:>10.4f}\")\n",
    "    \n",
    "    return g_losses, d_losses, fixed_noise, fixed_labels\n",
    "\n",
    "# Train cGAN\n",
    "cgan_g_losses, cgan_d_losses, cgan_fixed_noise, cgan_fixed_labels = train_cgan(\n",
    "    cgan_generator, cgan_discriminator, dataloader, epochs=30\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate specific digits with cGAN\n",
    "print(\"=\"*70)\n",
    "print(\"GENERATING SPECIFIC DIGITS WITH cGAN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "cgan_generator.eval()\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(12, 12))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for digit in range(10):\n",
    "        # Generate 10 samples of each digit\n",
    "        z = torch.randn(10, LATENT_DIM, device=device)\n",
    "        labels = torch.full((10,), digit, dtype=torch.long, device=device)\n",
    "        generated = cgan_generator(z, labels).cpu()\n",
    "        \n",
    "        for j in range(10):\n",
    "            img = generated[j].squeeze().numpy()\n",
    "            img = (img + 1) / 2\n",
    "            axes[digit, j].imshow(img, cmap='gray')\n",
    "            axes[digit, j].axis('off')\n",
    "        \n",
    "        # Label each row\n",
    "        axes[digit, 0].set_ylabel(f'{digit}', fontsize=12, fontweight='bold', rotation=0, labelpad=15)\n",
    "\n",
    "plt.suptitle('Conditional GAN: Generating Specific Digits (0-9)', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nEach row shows 10 different samples of the same digit!\")\n",
    "print(\"The cGAN learned to generate specific digits on demand.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part5'></a>\n",
    "# Part 5: GAN on Fashion-MNIST\n",
    "\n",
    "---\n",
    "\n",
    "Let's train DCGAN on a more challenging dataset - Fashion-MNIST (clothing items)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LOAD FASHION-MNIST\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"DCGAN ON FASHION-MNIST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Fashion-MNIST classes\n",
    "fashion_classes = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# Load Fashion-MNIST\n",
    "fashion_train = datasets.FashionMNIST(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "fashion_dataloader = DataLoader(\n",
    "    fashion_train, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(fashion_train):,}\")\n",
    "print(f\"Classes: {fashion_classes}\")\n",
    "\n",
    "# Show samples\n",
    "sample_batch, sample_labels = next(iter(fashion_dataloader))\n",
    "\n",
    "fig, axes = plt.subplots(2, 8, figsize=(12, 3))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = sample_batch[i].squeeze().numpy()\n",
    "    img = (img + 1) / 2\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'{fashion_classes[sample_labels[i]]}', fontsize=8)\n",
    "plt.suptitle('Sample Fashion-MNIST Images', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DCGAN for Fashion-MNIST\n",
    "fashion_generator = DCGenerator(LATENT_DIM, CHANNELS).to(device)\n",
    "fashion_discriminator = DCDiscriminator(CHANNELS).to(device)\n",
    "\n",
    "fashion_generator.apply(weights_init)\n",
    "fashion_discriminator.apply(weights_init)\n",
    "\n",
    "print(\"Training DCGAN on Fashion-MNIST...\")\n",
    "print(\"(This may take a few minutes)\\n\")\n",
    "\n",
    "# Train on Fashion-MNIST\n",
    "fashion_g_losses, fashion_d_losses, fashion_fixed_noise, fashion_history = train_dcgan(\n",
    "    fashion_generator, fashion_discriminator, fashion_dataloader, epochs=30\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Fashion-MNIST generation\n",
    "print(\"=\"*70)\n",
    "print(\"FASHION-MNIST GENERATED IMAGES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Training loss\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(fashion_g_losses, label='Generator', color='blue')\n",
    "ax1.plot(fashion_d_losses, label='Discriminator', color='red')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Fashion-MNIST DCGAN Training', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Real images\n",
    "ax2 = axes[0, 1]\n",
    "real_batch, _ = next(iter(fashion_dataloader))\n",
    "grid = make_grid(real_batch[:16], nrow=4, normalize=True, padding=2)\n",
    "ax2.imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Real Fashion Images', fontweight='bold')\n",
    "\n",
    "# Generated images\n",
    "ax3 = axes[1, 0]\n",
    "fashion_generator.eval()\n",
    "with torch.no_grad():\n",
    "    gen_fashion = fashion_generator(fashion_fixed_noise[:16]).cpu()\n",
    "grid = make_grid(gen_fashion, nrow=4, normalize=True, padding=2)\n",
    "ax3.imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Generated Fashion Images', fontweight='bold')\n",
    "\n",
    "# Training progression\n",
    "ax4 = axes[1, 1]\n",
    "if fashion_history:\n",
    "    final_epoch, final_imgs = fashion_history[-1]\n",
    "    grid = make_grid(final_imgs, nrow=4, normalize=True, padding=2)\n",
    "    ax4.imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "ax4.axis('off')\n",
    "ax4.set_title('Final Generated Images', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part6'></a>\n",
    "# Part 6: Training Tips & Tricks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GAN TRAINING TIPS\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"GAN TRAINING TIPS & TRICKS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "COMMON PROBLEMS AND SOLUTIONS:\n",
    "==============================\n",
    "\n",
    "1. MODE COLLAPSE:\n",
    "   Problem: Generator produces same image repeatedly\n",
    "   ┌─────────────────────────────────────────────────────────────┐\n",
    "   │ Solutions:                                                   │\n",
    "   │ - Use minibatch discrimination                              │\n",
    "   │ - Add noise to discriminator inputs                         │\n",
    "   │ - Use different learning rates for G and D                  │\n",
    "   │ - Use Wasserstein loss (WGAN)                               │\n",
    "   └─────────────────────────────────────────────────────────────┘\n",
    "\n",
    "2. TRAINING INSTABILITY:\n",
    "   Problem: Loss oscillates wildly, no convergence\n",
    "   ┌─────────────────────────────────────────────────────────────┐\n",
    "   │ Solutions:                                                   │\n",
    "   │ - Use soft labels (0.9 instead of 1.0)                      │\n",
    "   │ - Use label smoothing                                        │\n",
    "   │ - Gradient clipping                                          │\n",
    "   │ - Use spectral normalization                                 │\n",
    "   │ - Lower learning rate                                        │\n",
    "   └─────────────────────────────────────────────────────────────┘\n",
    "\n",
    "3. DISCRIMINATOR TOO STRONG:\n",
    "   Problem: D loss → 0, G can't learn\n",
    "   ┌─────────────────────────────────────────────────────────────┐\n",
    "   │ Solutions:                                                   │\n",
    "   │ - Train G more times per D update                           │\n",
    "   │ - Add dropout to D                                          │\n",
    "   │ - Reduce D capacity                                         │\n",
    "   │ - Use instance noise                                        │\n",
    "   └─────────────────────────────────────────────────────────────┘\n",
    "\n",
    "4. VANISHING GRADIENTS:\n",
    "   Problem: G receives near-zero gradients\n",
    "   ┌─────────────────────────────────────────────────────────────┐\n",
    "   │ Solutions:                                                   │\n",
    "   │ - Use LeakyReLU instead of ReLU                             │\n",
    "   │ - Use non-saturating loss: -log(D(G(z)))                    │\n",
    "   │ - Use Wasserstein loss                                      │\n",
    "   └─────────────────────────────────────────────────────────────┘\n",
    "\n",
    "BEST PRACTICES:\n",
    "===============\n",
    "✓ Normalize images to [-1, 1], use Tanh in G output\n",
    "✓ Use BatchNorm in both G and D (except D input, G output)\n",
    "✓ Use LeakyReLU (slope 0.2) in discriminator\n",
    "✓ Use Adam optimizer with β1=0.5\n",
    "✓ Use strided convolutions instead of pooling\n",
    "✓ Initialize weights from N(0, 0.02)\n",
    "✓ Track both D(x) and D(G(z)) during training\n",
    "✓ Save generated samples periodically\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part7'></a>\n",
    "# Part 7: Evaluation & Results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FINAL RESULTS COMPARISON\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL RESULTS - ALL MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Create grid spec\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Real MNIST\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "real_batch, _ = next(iter(dataloader))\n",
    "grid = make_grid(real_batch[:16], nrow=4, normalize=True, padding=2)\n",
    "ax1.imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Real MNIST', fontweight='bold')\n",
    "\n",
    "# 2. Basic GAN\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(16, LATENT_DIM, device=device)\n",
    "    basic_imgs = generator(noise).cpu()\n",
    "grid = make_grid(basic_imgs, nrow=4, normalize=True, padding=2)\n",
    "ax2.imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Basic GAN', fontweight='bold')\n",
    "\n",
    "# 3. DCGAN\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "dc_generator.eval()\n",
    "with torch.no_grad():\n",
    "    dc_imgs = dc_generator(noise).cpu()\n",
    "grid = make_grid(dc_imgs, nrow=4, normalize=True, padding=2)\n",
    "ax3.imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "ax3.axis('off')\n",
    "ax3.set_title('DCGAN', fontweight='bold')\n",
    "\n",
    "# 4. Conditional GAN - specific digits\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "cgan_generator.eval()\n",
    "with torch.no_grad():\n",
    "    # Generate one of each digit\n",
    "    z = torch.randn(10, LATENT_DIM, device=device)\n",
    "    labels = torch.arange(10, device=device)\n",
    "    cgan_imgs = cgan_generator(z, labels).cpu()\n",
    "grid = make_grid(cgan_imgs, nrow=5, normalize=True, padding=2)\n",
    "ax4.imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "ax4.axis('off')\n",
    "ax4.set_title('cGAN (digits 0-9)', fontweight='bold')\n",
    "\n",
    "# 5. Real Fashion-MNIST\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "real_fashion, _ = next(iter(fashion_dataloader))\n",
    "grid = make_grid(real_fashion[:16], nrow=4, normalize=True, padding=2)\n",
    "ax5.imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "ax5.axis('off')\n",
    "ax5.set_title('Real Fashion-MNIST', fontweight='bold')\n",
    "\n",
    "# 6. Generated Fashion\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "fashion_generator.eval()\n",
    "with torch.no_grad():\n",
    "    fashion_imgs = fashion_generator(noise).cpu()\n",
    "grid = make_grid(fashion_imgs, nrow=4, normalize=True, padding=2)\n",
    "ax6.imshow(grid.permute(1, 2, 0).numpy(), cmap='gray')\n",
    "ax6.axis('off')\n",
    "ax6.set_title('DCGAN Fashion', fontweight='bold')\n",
    "\n",
    "# 7. Training comparison\n",
    "ax7 = fig.add_subplot(gs[2, :])\n",
    "epochs = range(1, len(dc_g_losses) + 1)\n",
    "ax7.plot(epochs, dc_g_losses, 'b-', label='DCGAN MNIST - G', alpha=0.7)\n",
    "ax7.plot(epochs, dc_d_losses, 'b--', label='DCGAN MNIST - D', alpha=0.7)\n",
    "ax7.plot(epochs, fashion_g_losses, 'r-', label='DCGAN Fashion - G', alpha=0.7)\n",
    "ax7.plot(epochs, fashion_d_losses, 'r--', label='DCGAN Fashion - D', alpha=0.7)\n",
    "ax7.set_xlabel('Epoch')\n",
    "ax7.set_ylabel('Loss')\n",
    "ax7.set_title('Training Loss Comparison', fontweight='bold')\n",
    "ax7.legend(loc='upper right')\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('GAN Image Generation Results', fontweight='bold', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part8'></a>\n",
    "# Part 8: Summary\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\"*70)\n",
    "print(\"IMAGE GENERATION WITH GANs - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "WHAT WE LEARNED:\n",
    "================\n",
    "\n",
    "1. GAN FUNDAMENTALS:\n",
    "   ┌─────────────────────────────────────────────────────────────┐\n",
    "   │ Generator (G): Creates fake images from noise               │\n",
    "   │ Discriminator (D): Classifies real vs fake                  │\n",
    "   │ Training: Adversarial game - G vs D                         │\n",
    "   │ Goal: G fools D, both improve together                      │\n",
    "   └─────────────────────────────────────────────────────────────┘\n",
    "\n",
    "2. GAN ARCHITECTURES:\n",
    "   ┌─────────────────┬─────────────────────────────────────────┐\n",
    "   │ Basic GAN       │ Fully connected layers, simple          │\n",
    "   │ DCGAN           │ Convolutional layers, sharper images    │\n",
    "   │ Conditional GAN │ Control what to generate                │\n",
    "   └─────────────────┴─────────────────────────────────────────┘\n",
    "\n",
    "3. TRAINING PROCESS:\n",
    "   Step 1: Train D on real images (label = 1)\n",
    "   Step 2: Train D on fake images (label = 0)\n",
    "   Step 3: Train G to fool D (wants D output = 1)\n",
    "   Repeat!\n",
    "\n",
    "4. KEY LOSS FUNCTIONS:\n",
    "   D_loss = -[log(D(x)) + log(1 - D(G(z)))]\n",
    "   G_loss = -log(D(G(z)))  # or log(1 - D(G(z)))\n",
    "\n",
    "5. DCGAN RULES:\n",
    "   ✓ Use strided convolutions (no pooling)\n",
    "   ✓ Use BatchNorm (except D input, G output)\n",
    "   ✓ Use LeakyReLU in D, ReLU in G\n",
    "   ✓ Use Tanh output in G (images in [-1, 1])\n",
    "\n",
    "6. EVALUATION METRICS:\n",
    "   - Inception Score (IS): Higher is better\n",
    "   - Fréchet Inception Distance (FID): Lower is better\n",
    "   - Visual inspection: Most practical!\n",
    "\n",
    "MODERN GAN VARIANTS:\n",
    "====================\n",
    "- WGAN: Wasserstein loss for stable training\n",
    "- StyleGAN: High-quality face generation\n",
    "- CycleGAN: Unpaired image-to-image translation\n",
    "- BigGAN: Large-scale image synthesis\n",
    "- Diffusion Models: Now state-of-the-art (DALL-E, Stable Diffusion)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nMODEL COMPARISON:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Model':<20} {'Dataset':<15} {'Quality':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Basic GAN':<20} {'MNIST':<15} {'Blurry digits':<15}\")\n",
    "print(f\"{'DCGAN':<20} {'MNIST':<15} {'Clear digits':<15}\")\n",
    "print(f\"{'Conditional GAN':<20} {'MNIST':<15} {'Specific digits':<15}\")\n",
    "print(f\"{'DCGAN':<20} {'Fashion-MNIST':<15} {'Clothing items':<15}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm & Method Taxonomy\n",
    "\n",
    "### GAN Architectures\n",
    "\n",
    "| Architecture | Key Feature | Best For |\n",
    "|--------------|-------------|----------|\n",
    "| **Basic GAN** | Fully connected | Simple distributions |\n",
    "| **DCGAN** | Convolutional | Image generation |\n",
    "| **cGAN** | Conditional input | Class-specific generation |\n",
    "| **WGAN** | Wasserstein loss | Stable training |\n",
    "| **StyleGAN** | Style mixing | High-quality faces |\n",
    "| **CycleGAN** | Cycle consistency | Image translation |\n",
    "\n",
    "### Loss Functions\n",
    "\n",
    "| Loss | Formula | Pros/Cons |\n",
    "|------|---------|----------|\n",
    "| **BCE** | -log(D(x)) | Standard, can saturate |\n",
    "| **Non-saturating** | -log(D(G(z))) | Better gradients for G |\n",
    "| **Wasserstein** | E[D(x)] - E[D(G(z))] | Stable, needs clipping |\n",
    "| **Hinge** | max(0, 1-D(x)) | Works well in practice |\n",
    "\n",
    "### Training Stability Techniques\n",
    "\n",
    "| Technique | Purpose |\n",
    "|-----------|--------|\n",
    "| **Label smoothing** | Prevent D overconfidence |\n",
    "| **Instance noise** | Regularize D |\n",
    "| **Spectral norm** | Stabilize D gradients |\n",
    "| **Two timescale** | Different LR for G and D |\n",
    "| **Progressive growing** | Start small, grow resolution |\n",
    "\n",
    "---\n",
    "\n",
    "## Checklist\n",
    "\n",
    "- [x] Understand GAN fundamentals (G vs D game)\n",
    "- [x] Implement basic GAN from scratch\n",
    "- [x] Implement DCGAN with convolutions\n",
    "- [x] Implement conditional GAN\n",
    "- [x] Train on MNIST and Fashion-MNIST\n",
    "- [x] Know common training problems and solutions\n",
    "- [x] Generate recognizable images\n",
    "\n",
    "---\n",
    "\n",
    "**End of Image Generation with GANs Tutorial**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
