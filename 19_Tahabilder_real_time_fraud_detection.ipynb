{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 19: Real-Time Fraud Detection System\n",
    "\n",
    "**Detect fraudulent transactions using real-time data**\n",
    "\n",
    "In this tutorial, we'll build a complete fraud detection system that can:\n",
    "- Handle highly imbalanced data (fraud is rare!)\n",
    "- Detect fraudulent transactions in real-time\n",
    "- Optimize for business metrics (minimize false negatives)\n",
    "- Process streaming transactions\n",
    "\n",
    "**Dataset**: Credit Card Fraud Detection (Kaggle)\n",
    "- 284,807 transactions\n",
    "- Only 492 frauds (0.172% - highly imbalanced!)\n",
    "- Features V1-V28: PCA transformed (anonymized)\n",
    "- Time: Seconds since first transaction\n",
    "- Amount: Transaction amount\n",
    "- Class: 0 = Normal, 1 = Fraud\n",
    "\n",
    "**Key Challenges**:\n",
    "1. Extreme class imbalance (99.83% vs 0.17%)\n",
    "2. Real-time prediction requirements\n",
    "3. High cost of false negatives (missed fraud)\n",
    "4. Need for interpretable decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Data Loading](#1-setup-and-data-loading)\n",
    "2. [Exploratory Data Analysis](#2-exploratory-data-analysis)\n",
    "3. [Data Preprocessing](#3-data-preprocessing)\n",
    "4. [Handling Class Imbalance](#4-handling-class-imbalance)\n",
    "5. [Model Building](#5-model-building)\n",
    "6. [Model Evaluation](#6-model-evaluation)\n",
    "7. [Threshold Optimization](#7-threshold-optimization)\n",
    "8. [Real-Time Detection Pipeline](#8-real-time-detection-pipeline)\n",
    "9. [Streaming Simulation](#9-streaming-simulation)\n",
    "10. [Summary](#10-summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q kagglehub imbalanced-learn xgboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    precision_recall_curve, roc_curve, auc, f1_score,\n",
    "    precision_score, recall_score, average_precision_score\n",
    ")\n",
    "\n",
    "# Imbalanced learning\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "\n",
    "# Set random seeds\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Credit Card Fraud dataset\n",
    "import os\n",
    "\n",
    "# Check if running on Kaggle\n",
    "USE_KAGGLE = os.path.exists('/kaggle/input')\n",
    "\n",
    "if USE_KAGGLE:\n",
    "    # Direct path on Kaggle\n",
    "    try:\n",
    "        df = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\n",
    "        print(\"Loaded from Kaggle input directory\")\n",
    "    except:\n",
    "        import kagglehub\n",
    "        from kagglehub import KaggleDatasetAdapter\n",
    "        df = kagglehub.load_dataset(\n",
    "            KaggleDatasetAdapter.PANDAS,\n",
    "            \"mlg-ulb/creditcardfraud\",\n",
    "            \"\",\n",
    "        )\n",
    "        print(\"Loaded via kagglehub\")\n",
    "else:\n",
    "    # Try kagglehub\n",
    "    try:\n",
    "        import kagglehub\n",
    "        from kagglehub import KaggleDatasetAdapter\n",
    "        df = kagglehub.load_dataset(\n",
    "            KaggleDatasetAdapter.PANDAS,\n",
    "            \"mlg-ulb/creditcardfraud\",\n",
    "            \"\",\n",
    "        )\n",
    "        print(\"Loaded via kagglehub\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load via kagglehub: {e}\")\n",
    "        print(\"Please download the dataset manually from:\")\n",
    "        print(\"https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud\")\n",
    "        # Create sample data for demonstration\n",
    "        print(\"\\nCreating synthetic fraud data for demonstration...\")\n",
    "        n_samples = 10000\n",
    "        n_fraud = int(n_samples * 0.002)  # 0.2% fraud rate\n",
    "        \n",
    "        # Generate features\n",
    "        np.random.seed(SEED)\n",
    "        normal_data = np.random.randn(n_samples - n_fraud, 28)\n",
    "        fraud_data = np.random.randn(n_fraud, 28) + np.random.choice([-2, 2], size=(n_fraud, 28))\n",
    "        \n",
    "        V_cols = [f'V{i}' for i in range(1, 29)]\n",
    "        df_normal = pd.DataFrame(normal_data, columns=V_cols)\n",
    "        df_normal['Class'] = 0\n",
    "        df_fraud = pd.DataFrame(fraud_data, columns=V_cols)\n",
    "        df_fraud['Class'] = 1\n",
    "        \n",
    "        df = pd.concat([df_normal, df_fraud], ignore_index=True)\n",
    "        df['Time'] = np.arange(len(df))\n",
    "        df['Amount'] = np.abs(np.random.exponential(100, len(df)))\n",
    "        df = df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print(\"Dataset Overview\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total transactions: {len(df):,}\")\n",
    "print(f\"Features: {df.shape[1]}\")\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution - THE KEY CHALLENGE\n",
    "print(\"\\nClass Distribution (Target Variable)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "class_counts = df['Class'].value_counts()\n",
    "class_pcts = df['Class'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(f\"Normal transactions (0): {class_counts[0]:,} ({class_pcts[0]:.3f}%)\")\n",
    "print(f\"Fraud transactions (1):  {class_counts[1]:,} ({class_pcts[1]:.3f}%)\")\n",
    "print(f\"\\nImbalance ratio: 1:{class_counts[0]//class_counts[1]}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Count plot\n",
    "ax1 = axes[0]\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "bars = ax1.bar(['Normal', 'Fraud'], class_counts.values, color=colors)\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Transaction Class Distribution')\n",
    "for bar, count in zip(bars, class_counts.values):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1000, \n",
    "             f'{count:,}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Pie chart (log scale visual)\n",
    "ax2 = axes[1]\n",
    "ax2.pie(class_pcts.values, labels=['Normal', 'Fraud'], autopct='%1.2f%%',\n",
    "        colors=colors, explode=[0, 0.1], shadow=True)\n",
    "ax2.set_title('Class Percentage')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n*** This extreme imbalance is the main challenge! ***\")\n",
    "print(\"A naive model predicting all 'Normal' would be 99.83% accurate but useless!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Time and Amount features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Time distribution\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(df[df['Class']==0]['Time'], bins=50, alpha=0.7, label='Normal', color='#2ecc71')\n",
    "ax1.hist(df[df['Class']==1]['Time'], bins=50, alpha=0.7, label='Fraud', color='#e74c3c')\n",
    "ax1.set_xlabel('Time (seconds from first transaction)')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Transaction Time Distribution')\n",
    "ax1.legend()\n",
    "\n",
    "# Amount distribution (log scale)\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(df[df['Class']==0]['Amount'], bins=50, alpha=0.7, label='Normal', color='#2ecc71')\n",
    "ax2.hist(df[df['Class']==1]['Amount'], bins=50, alpha=0.7, label='Fraud', color='#e74c3c')\n",
    "ax2.set_xlabel('Amount')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title('Transaction Amount Distribution')\n",
    "ax2.set_yscale('log')\n",
    "ax2.legend()\n",
    "\n",
    "# Amount boxplot by class\n",
    "ax3 = axes[1, 0]\n",
    "df.boxplot(column='Amount', by='Class', ax=ax3)\n",
    "ax3.set_title('Amount by Class')\n",
    "ax3.set_xlabel('Class (0=Normal, 1=Fraud)')\n",
    "plt.suptitle('')\n",
    "\n",
    "# Amount statistics\n",
    "ax4 = axes[1, 1]\n",
    "amount_stats = df.groupby('Class')['Amount'].describe()\n",
    "ax4.axis('off')\n",
    "table = ax4.table(cellText=amount_stats.round(2).values,\n",
    "                  colLabels=amount_stats.columns,\n",
    "                  rowLabels=['Normal', 'Fraud'],\n",
    "                  cellLoc='center',\n",
    "                  loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1.2, 1.5)\n",
    "ax4.set_title('Amount Statistics by Class', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(f\"  - Fraud transactions tend to have lower amounts\")\n",
    "print(f\"  - Mean fraud amount: ${df[df['Class']==1]['Amount'].mean():.2f}\")\n",
    "print(f\"  - Mean normal amount: ${df[df['Class']==0]['Amount'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze PCA features (V1-V28)\n",
    "v_features = [f'V{i}' for i in range(1, 29)]\n",
    "\n",
    "# Correlation with target\n",
    "correlations = df[v_features + ['Class']].corr()['Class'].drop('Class').sort_values()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Correlation bar plot\n",
    "ax1 = axes[0]\n",
    "colors = ['#e74c3c' if x < 0 else '#2ecc71' for x in correlations.values]\n",
    "ax1.barh(correlations.index, correlations.values, color=colors)\n",
    "ax1.set_xlabel('Correlation with Fraud')\n",
    "ax1.set_title('Feature Correlation with Fraud Class')\n",
    "ax1.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# Top features distribution\n",
    "ax2 = axes[1]\n",
    "top_features = correlations.abs().nlargest(5).index.tolist()\n",
    "for feat in top_features:\n",
    "    fraud_vals = df[df['Class']==1][feat]\n",
    "    ax2.hist(fraud_vals, bins=30, alpha=0.5, label=feat, density=True)\n",
    "ax2.set_xlabel('Feature Value')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title('Top Correlated Features (Fraud Only)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop features correlated with fraud:\")\n",
    "print(correlations.abs().nlargest(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "print(\"Data Preprocessing\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Scale Amount and Time (V1-V28 already scaled via PCA)\n",
    "scaler_amount = RobustScaler()  # Robust to outliers\n",
    "scaler_time = StandardScaler()\n",
    "\n",
    "X['Amount_scaled'] = scaler_amount.fit_transform(X[['Amount']])\n",
    "X['Time_scaled'] = scaler_time.fit_transform(X[['Time']])\n",
    "\n",
    "# Drop original Amount and Time\n",
    "X = X.drop(['Amount', 'Time'], axis=1)\n",
    "\n",
    "print(f\"\\nFeatures after scaling: {X.shape[1]}\")\n",
    "print(f\"Feature names: {X.columns.tolist()[:5]}... (and {len(X.columns)-5} more)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (stratified to maintain class ratio)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train-Test Split (Stratified)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"  - Normal: {(y_train==0).sum():,} ({(y_train==0).mean()*100:.2f}%)\")\n",
    "print(f\"  - Fraud:  {(y_train==1).sum():,} ({(y_train==1).mean()*100:.2f}%)\")\n",
    "print(f\"\\nTest set: {X_test.shape[0]:,} samples\")\n",
    "print(f\"  - Normal: {(y_test==0).sum():,} ({(y_test==0).mean()*100:.2f}%)\")\n",
    "print(f\"  - Fraud:  {(y_test==1).sum():,} ({(y_test==1).mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handling Class Imbalance\n",
    "\n",
    "Several techniques to handle the extreme imbalance:\n",
    "\n",
    "1. **Oversampling**: Create synthetic fraud samples (SMOTE)\n",
    "2. **Undersampling**: Reduce normal samples\n",
    "3. **Class Weights**: Penalize misclassifying minority class\n",
    "4. **Threshold Adjustment**: Lower decision threshold for fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate different sampling techniques\n",
    "print(\"Sampling Techniques for Class Imbalance\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Original distribution\n",
    "print(f\"\\nOriginal: {y_train.value_counts().to_dict()}\")\n",
    "\n",
    "# 1. SMOTE (Synthetic Minority Oversampling)\n",
    "smote = SMOTE(random_state=SEED, sampling_strategy=0.5)  # 50% of majority\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "print(f\"SMOTE:    {pd.Series(y_smote).value_counts().to_dict()}\")\n",
    "\n",
    "# 2. Random Undersampling\n",
    "rus = RandomUnderSampler(random_state=SEED, sampling_strategy=0.5)\n",
    "X_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
    "print(f\"Undersample: {pd.Series(y_rus).value_counts().to_dict()}\")\n",
    "\n",
    "# 3. SMOTE + Tomek Links (combined)\n",
    "smt = SMOTETomek(random_state=SEED)\n",
    "X_smt, y_smt = smt.fit_resample(X_train, y_train)\n",
    "print(f\"SMOTETomek: {pd.Series(y_smt).value_counts().to_dict()}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "datasets = [\n",
    "    ('Original', y_train),\n",
    "    ('SMOTE', y_smote),\n",
    "    ('Undersampling', y_rus),\n",
    "    ('SMOTETomek', y_smt)\n",
    "]\n",
    "\n",
    "for ax, (name, y_data) in zip(axes, datasets):\n",
    "    counts = pd.Series(y_data).value_counts()\n",
    "    ax.bar(['Normal', 'Fraud'], counts.values, color=['#2ecc71', '#e74c3c'])\n",
    "    ax.set_title(f'{name}\\n({len(y_data):,} samples)')\n",
    "    ax.set_ylabel('Count')\n",
    "    for i, v in enumerate(counts.values):\n",
    "        ax.text(i, v + 100, f'{v:,}', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights for algorithms that support it\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "print(\"Class Weights (for algorithms that support it):\")\n",
    "print(f\"  Normal (0): {class_weight_dict[0]:.4f}\")\n",
    "print(f\"  Fraud (1):  {class_weight_dict[1]:.4f}\")\n",
    "print(f\"\\nThis means fraud samples are weighted {class_weight_dict[1]/class_weight_dict[0]:.0f}x more!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Building\n",
    "\n",
    "We'll train multiple models and compare their performance:\n",
    "1. Logistic Regression (baseline)\n",
    "2. Random Forest\n",
    "3. XGBoost\n",
    "4. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store models and results\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "def evaluate_model(name, model, X_test, y_test, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate model and return metrics.\n",
    "    \"\"\"\n",
    "    # Predictions\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_proba = model.predict(X_test)\n",
    "    \n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    # Metrics\n",
    "    metrics = {\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1': f1_score(y_test, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_test, y_proba),\n",
    "        'pr_auc': average_precision_score(y_test, y_proba),\n",
    "        'y_proba': y_proba,\n",
    "        'y_pred': y_pred\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"Model training functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logistic Regression (with class weights)\n",
    "print(\"Training Model 1: Logistic Regression\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "lr_model.fit(X_train, y_train)\n",
    "models['Logistic Regression'] = lr_model\n",
    "\n",
    "results['Logistic Regression'] = evaluate_model('Logistic Regression', lr_model, X_test, y_test)\n",
    "print(f\"ROC-AUC: {results['Logistic Regression']['roc_auc']:.4f}\")\n",
    "print(f\"PR-AUC:  {results['Logistic Regression']['pr_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Random Forest (with class weights)\n",
    "print(\"Training Model 2: Random Forest\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    class_weight='balanced',\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "models['Random Forest'] = rf_model\n",
    "\n",
    "results['Random Forest'] = evaluate_model('Random Forest', rf_model, X_test, y_test)\n",
    "print(f\"ROC-AUC: {results['Random Forest']['roc_auc']:.4f}\")\n",
    "print(f\"PR-AUC:  {results['Random Forest']['pr_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. XGBoost (with scale_pos_weight)\n",
    "print(\"Training Model 3: XGBoost\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate scale_pos_weight\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='auc'\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "models['XGBoost'] = xgb_model\n",
    "\n",
    "results['XGBoost'] = evaluate_model('XGBoost', xgb_model, X_test, y_test)\n",
    "print(f\"ROC-AUC: {results['XGBoost']['roc_auc']:.4f}\")\n",
    "print(f\"PR-AUC:  {results['XGBoost']['pr_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Neural Network with SMOTE\n",
    "print(\"Training Model 4: Neural Network (with SMOTE)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class FraudDetectionNN(nn.Module):\n",
    "    \"\"\"Neural network for fraud detection.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        super(FraudDetectionNN, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Apply SMOTE for neural network training\n",
    "smote = SMOTE(random_state=SEED, sampling_strategy=0.3)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_smote.values).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train_smote.values).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test.values).to(device)\n",
    "\n",
    "# Create model\n",
    "nn_model = FraudDetectionNN(X_train.shape[1]).to(device)\n",
    "\n",
    "# Loss with class weights\n",
    "pos_weight = torch.tensor([class_weight_dict[1] / class_weight_dict[0]]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = optim.Adam(nn_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training\n",
    "batch_size = 256\n",
    "n_epochs = 20\n",
    "\n",
    "dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "nn_model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = nn_model(batch_X).squeeze()\n",
    "        loss = nn.BCELoss()(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "nn_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_proba_nn = nn_model(X_test_tensor).cpu().numpy().squeeze()\n",
    "\n",
    "# Store results\n",
    "y_pred_nn = (y_proba_nn >= 0.5).astype(int)\n",
    "results['Neural Network'] = {\n",
    "    'precision': precision_score(y_test, y_pred_nn),\n",
    "    'recall': recall_score(y_test, y_pred_nn),\n",
    "    'f1': f1_score(y_test, y_pred_nn),\n",
    "    'roc_auc': roc_auc_score(y_test, y_proba_nn),\n",
    "    'pr_auc': average_precision_score(y_test, y_proba_nn),\n",
    "    'y_proba': y_proba_nn,\n",
    "    'y_pred': y_pred_nn\n",
    "}\n",
    "models['Neural Network'] = nn_model\n",
    "\n",
    "print(f\"\\nROC-AUC: {results['Neural Network']['roc_auc']:.4f}\")\n",
    "print(f\"PR-AUC:  {results['Neural Network']['pr_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "For imbalanced fraud detection, we focus on:\n",
    "- **Precision-Recall** (not ROC-AUC alone!)\n",
    "- **Recall** (catch as many frauds as possible)\n",
    "- **Confusion Matrix** (see false negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "print(\"Model Comparison\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    name: {\n",
    "        'Precision': res['precision'],\n",
    "        'Recall': res['recall'],\n",
    "        'F1-Score': res['f1'],\n",
    "        'ROC-AUC': res['roc_auc'],\n",
    "        'PR-AUC': res['pr_auc']\n",
    "    }\n",
    "    for name, res in results.items()\n",
    "}).T\n",
    "\n",
    "print(comparison_df.round(4).to_string())\n",
    "\n",
    "# Highlight best\n",
    "print(\"\\nBest Models:\")\n",
    "for metric in comparison_df.columns:\n",
    "    best = comparison_df[metric].idxmax()\n",
    "    print(f\"  {metric}: {best} ({comparison_df.loc[best, metric]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and PR Curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "colors = ['#3498db', '#2ecc71', '#e74c3c', '#9b59b6']\n",
    "\n",
    "# ROC Curves\n",
    "ax1 = axes[0]\n",
    "for (name, res), color in zip(results.items(), colors):\n",
    "    fpr, tpr, _ = roc_curve(y_test, res['y_proba'])\n",
    "    ax1.plot(fpr, tpr, label=f\"{name} (AUC={res['roc_auc']:.3f})\", color=color, linewidth=2)\n",
    "\n",
    "ax1.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('ROC Curves')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curves\n",
    "ax2 = axes[1]\n",
    "for (name, res), color in zip(results.items(), colors):\n",
    "    precision, recall, _ = precision_recall_curve(y_test, res['y_proba'])\n",
    "    ax2.plot(recall, precision, label=f\"{name} (AP={res['pr_auc']:.3f})\", color=color, linewidth=2)\n",
    "\n",
    "# Baseline (random classifier)\n",
    "baseline = y_test.mean()\n",
    "ax2.axhline(y=baseline, color='k', linestyle='--', label=f'Baseline ({baseline:.4f})')\n",
    "\n",
    "ax2.set_xlabel('Recall')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.set_title('Precision-Recall Curves (More Important for Imbalanced Data!)')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNote: PR-AUC is more informative than ROC-AUC for imbalanced datasets!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for ax, (name, res) in zip(axes.flatten(), results.items()):\n",
    "    cm = confusion_matrix(y_test, res['y_pred'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Normal', 'Fraud'],\n",
    "                yticklabels=['Normal', 'Fraud'])\n",
    "    ax.set_title(f'{name}')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    \n",
    "    # Add metrics\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    ax.text(0.5, -0.15, f'FN (Missed Fraud): {fn} | FP (False Alarm): {fp}',\n",
    "            transform=ax.transAxes, ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Key Metrics for Fraud Detection:\")\n",
    "print(\"  - False Negatives (FN): Missed frauds - VERY COSTLY!\")\n",
    "print(\"  - False Positives (FP): False alarms - Annoying but less costly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Threshold Optimization\n",
    "\n",
    "The default threshold of 0.5 may not be optimal. For fraud detection:\n",
    "- **Lower threshold** = Catch more fraud (higher recall) but more false alarms\n",
    "- **Higher threshold** = Fewer false alarms but miss more fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_threshold(y_true, y_proba, metric='f1'):\n",
    "    \"\"\"\n",
    "    Find optimal classification threshold.\n",
    "    \n",
    "    Args:\n",
    "        metric: 'f1', 'recall', or 'precision'\n",
    "    \"\"\"\n",
    "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "    scores = []\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        y_pred = (y_proba >= thresh).astype(int)\n",
    "        if metric == 'f1':\n",
    "            score = f1_score(y_true, y_pred)\n",
    "        elif metric == 'recall':\n",
    "            score = recall_score(y_true, y_pred)\n",
    "        elif metric == 'precision':\n",
    "            score = precision_score(y_true, y_pred)\n",
    "        scores.append(score)\n",
    "    \n",
    "    best_idx = np.argmax(scores)\n",
    "    return thresholds[best_idx], scores[best_idx], thresholds, scores\n",
    "\n",
    "# Find optimal thresholds for best model (XGBoost)\n",
    "best_model_name = comparison_df['PR-AUC'].idxmax()\n",
    "y_proba_best = results[best_model_name]['y_proba']\n",
    "\n",
    "print(f\"Threshold Optimization for {best_model_name}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot threshold vs metrics\n",
    "ax1 = axes[0]\n",
    "for metric, color in [('f1', 'blue'), ('recall', 'green'), ('precision', 'red')]:\n",
    "    opt_thresh, opt_score, thresholds, scores = find_optimal_threshold(y_test, y_proba_best, metric)\n",
    "    ax1.plot(thresholds, scores, label=f'{metric.capitalize()} (opt={opt_thresh:.2f})', color=color)\n",
    "    ax1.axvline(x=opt_thresh, color=color, linestyle='--', alpha=0.5)\n",
    "\n",
    "ax1.axvline(x=0.5, color='black', linestyle='-', alpha=0.3, label='Default (0.5)')\n",
    "ax1.set_xlabel('Threshold')\n",
    "ax1.set_ylabel('Score')\n",
    "ax1.set_title('Metrics vs Threshold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Business cost analysis\n",
    "ax2 = axes[1]\n",
    "\n",
    "# Assume: Cost of missed fraud = $500, Cost of false alarm = $10\n",
    "cost_fn = 500  # False Negative cost\n",
    "cost_fp = 10   # False Positive cost\n",
    "\n",
    "costs = []\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_pred = (y_proba_best >= thresh).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    total_cost = (fn * cost_fn) + (fp * cost_fp)\n",
    "    costs.append(total_cost)\n",
    "\n",
    "ax2.plot(thresholds, costs, color='purple', linewidth=2)\n",
    "opt_idx = np.argmin(costs)\n",
    "ax2.axvline(x=thresholds[opt_idx], color='red', linestyle='--', \n",
    "            label=f'Optimal: {thresholds[opt_idx]:.2f}')\n",
    "ax2.scatter([thresholds[opt_idx]], [costs[opt_idx]], color='red', s=100, zorder=5)\n",
    "\n",
    "ax2.set_xlabel('Threshold')\n",
    "ax2.set_ylabel('Total Cost ($)')\n",
    "ax2.set_title(f'Business Cost Analysis\\n(FN=${cost_fn}, FP=${cost_fp})')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOptimal threshold (minimum cost): {thresholds[opt_idx]:.2f}\")\n",
    "print(f\"Minimum total cost: ${costs[opt_idx]:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare default vs optimized threshold\n",
    "optimal_threshold = thresholds[opt_idx]\n",
    "\n",
    "print(\"Performance Comparison: Default vs Optimized Threshold\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for thresh, name in [(0.5, 'Default (0.5)'), (optimal_threshold, f'Optimized ({optimal_threshold:.2f})')]:\n",
    "    y_pred = (y_proba_best >= thresh).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"  Recall:    {recall_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"  F1-Score:  {f1_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"  Missed Frauds (FN): {fn}\")\n",
    "    print(f\"  False Alarms (FP): {fp}\")\n",
    "    print(f\"  Total Cost: ${(fn * cost_fn) + (fp * cost_fp):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Real-Time Detection Pipeline\n",
    "\n",
    "Now let's build a production-ready pipeline for real-time fraud detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeFraudDetector:\n",
    "    \"\"\"\n",
    "    Real-time fraud detection system.\n",
    "    \n",
    "    Features:\n",
    "    - Fast prediction for streaming transactions\n",
    "    - Configurable threshold\n",
    "    - Risk scoring\n",
    "    - Transaction history tracking\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, scaler_amount, scaler_time, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Initialize fraud detector.\n",
    "        \n",
    "        Args:\n",
    "            model: Trained classifier\n",
    "            scaler_amount: Fitted scaler for Amount\n",
    "            scaler_time: Fitted scaler for Time\n",
    "            threshold: Classification threshold\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.scaler_amount = scaler_amount\n",
    "        self.scaler_time = scaler_time\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # Statistics tracking\n",
    "        self.total_transactions = 0\n",
    "        self.total_flagged = 0\n",
    "        self.transaction_history = []\n",
    "        \n",
    "    def preprocess(self, transaction):\n",
    "        \"\"\"\n",
    "        Preprocess a single transaction.\n",
    "        \n",
    "        Args:\n",
    "            transaction: dict with keys 'V1'-'V28', 'Amount', 'Time'\n",
    "            \n",
    "        Returns:\n",
    "            numpy array ready for prediction\n",
    "        \"\"\"\n",
    "        # Extract features\n",
    "        features = [transaction.get(f'V{i}', 0) for i in range(1, 29)]\n",
    "        \n",
    "        # Scale Amount and Time\n",
    "        amount_scaled = self.scaler_amount.transform([[transaction['Amount']]])[0][0]\n",
    "        time_scaled = self.scaler_time.transform([[transaction['Time']]])[0][0]\n",
    "        \n",
    "        features.extend([amount_scaled, time_scaled])\n",
    "        \n",
    "        return np.array(features).reshape(1, -1)\n",
    "    \n",
    "    def predict(self, transaction):\n",
    "        \"\"\"\n",
    "        Predict if transaction is fraudulent.\n",
    "        \n",
    "        Returns:\n",
    "            dict with prediction results\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Preprocess\n",
    "        features = self.preprocess(transaction)\n",
    "        \n",
    "        # Get probability\n",
    "        if hasattr(self.model, 'predict_proba'):\n",
    "            fraud_prob = self.model.predict_proba(features)[0][1]\n",
    "        else:\n",
    "            fraud_prob = self.model.predict(features)[0]\n",
    "        \n",
    "        # Classification\n",
    "        is_fraud = fraud_prob >= self.threshold\n",
    "        \n",
    "        # Risk level\n",
    "        if fraud_prob < 0.3:\n",
    "            risk_level = 'LOW'\n",
    "        elif fraud_prob < 0.6:\n",
    "            risk_level = 'MEDIUM'\n",
    "        elif fraud_prob < 0.8:\n",
    "            risk_level = 'HIGH'\n",
    "        else:\n",
    "            risk_level = 'CRITICAL'\n",
    "        \n",
    "        # Update statistics\n",
    "        self.total_transactions += 1\n",
    "        if is_fraud:\n",
    "            self.total_flagged += 1\n",
    "        \n",
    "        prediction_time = (time.time() - start_time) * 1000  # ms\n",
    "        \n",
    "        result = {\n",
    "            'transaction_id': self.total_transactions,\n",
    "            'amount': transaction['Amount'],\n",
    "            'fraud_probability': fraud_prob,\n",
    "            'is_fraud': is_fraud,\n",
    "            'risk_level': risk_level,\n",
    "            'prediction_time_ms': prediction_time,\n",
    "            'action': 'BLOCK' if is_fraud else 'ALLOW'\n",
    "        }\n",
    "        \n",
    "        self.transaction_history.append(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_statistics(self):\n",
    "        \"\"\"Get detection statistics.\"\"\"\n",
    "        return {\n",
    "            'total_transactions': self.total_transactions,\n",
    "            'total_flagged': self.total_flagged,\n",
    "            'fraud_rate': self.total_flagged / max(1, self.total_transactions),\n",
    "            'avg_prediction_time_ms': np.mean([t['prediction_time_ms'] for t in self.transaction_history]) if self.transaction_history else 0\n",
    "        }\n",
    "    \n",
    "    def reset_statistics(self):\n",
    "        \"\"\"Reset tracking statistics.\"\"\"\n",
    "        self.total_transactions = 0\n",
    "        self.total_flagged = 0\n",
    "        self.transaction_history = []\n",
    "\n",
    "# Create detector with best model\n",
    "detector = RealTimeFraudDetector(\n",
    "    model=models[best_model_name],\n",
    "    scaler_amount=scaler_amount,\n",
    "    scaler_time=scaler_time,\n",
    "    threshold=optimal_threshold\n",
    ")\n",
    "\n",
    "print(f\"Real-Time Fraud Detector initialized!\")\n",
    "print(f\"  Model: {best_model_name}\")\n",
    "print(f\"  Threshold: {optimal_threshold:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample transactions\n",
    "print(\"Testing Real-Time Fraud Detection\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get some test transactions\n",
    "test_indices = y_test.reset_index(drop=True)\n",
    "fraud_indices = test_indices[test_indices == 1].index[:3].tolist()\n",
    "normal_indices = test_indices[test_indices == 0].index[:3].tolist()\n",
    "\n",
    "test_samples = fraud_indices + normal_indices\n",
    "\n",
    "for idx in test_samples:\n",
    "    # Create transaction dict\n",
    "    row = df.iloc[X_test.index[idx]]\n",
    "    transaction = {\n",
    "        'Time': row['Time'],\n",
    "        'Amount': row['Amount'],\n",
    "        **{f'V{i}': row[f'V{i}'] for i in range(1, 29)}\n",
    "    }\n",
    "    \n",
    "    # Predict\n",
    "    result = detector.predict(transaction)\n",
    "    actual = 'FRAUD' if y_test.iloc[idx] == 1 else 'NORMAL'\n",
    "    \n",
    "    print(f\"\\nTransaction #{result['transaction_id']}:\")\n",
    "    print(f\"  Amount: ${result['amount']:.2f}\")\n",
    "    print(f\"  Fraud Probability: {result['fraud_probability']:.4f}\")\n",
    "    print(f\"  Risk Level: {result['risk_level']}\")\n",
    "    print(f\"  Prediction: {result['action']} | Actual: {actual}\")\n",
    "    print(f\"  Time: {result['prediction_time_ms']:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Streaming Simulation\n",
    "\n",
    "Simulate real-time transaction processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_transaction_stream(detector, X_data, y_data, n_transactions=100, delay=0.01):\n",
    "    \"\"\"\n",
    "    Simulate streaming transactions.\n",
    "    \n",
    "    Args:\n",
    "        detector: FraudDetector instance\n",
    "        X_data: Feature data\n",
    "        y_data: Labels\n",
    "        n_transactions: Number of transactions to process\n",
    "        delay: Delay between transactions (seconds)\n",
    "    \"\"\"\n",
    "    detector.reset_statistics()\n",
    "    \n",
    "    # Sample transactions\n",
    "    indices = np.random.choice(len(X_data), min(n_transactions, len(X_data)), replace=False)\n",
    "    \n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    print(f\"Processing {n_transactions} transactions...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        # Get transaction\n",
    "        row = df.iloc[X_data.index[idx]]\n",
    "        transaction = {\n",
    "            'Time': row['Time'],\n",
    "            'Amount': row['Amount'],\n",
    "            **{f'V{i}': row[f'V{i}'] for i in range(1, 29)}\n",
    "        }\n",
    "        \n",
    "        # Predict\n",
    "        result = detector.predict(transaction)\n",
    "        actual_fraud = y_data.iloc[idx] == 1\n",
    "        predicted_fraud = result['is_fraud']\n",
    "        \n",
    "        # Track metrics\n",
    "        if actual_fraud and predicted_fraud:\n",
    "            true_positives += 1\n",
    "        elif not actual_fraud and predicted_fraud:\n",
    "            false_positives += 1\n",
    "        elif actual_fraud and not predicted_fraud:\n",
    "            false_negatives += 1\n",
    "        else:\n",
    "            true_negatives += 1\n",
    "        \n",
    "        # Print alerts for fraud\n",
    "        if result['risk_level'] in ['HIGH', 'CRITICAL']:\n",
    "            status = \"CAUGHT!\" if actual_fraud else \"False Alarm\"\n",
    "            print(f\"  [{result['risk_level']}] Transaction #{result['transaction_id']}: \"\n",
    "                  f\"${result['amount']:.2f} - {result['action']} ({status})\")\n",
    "        \n",
    "        # Progress\n",
    "        if (i + 1) % 200 == 0:\n",
    "            print(f\"  Processed {i + 1}/{n_transactions}...\")\n",
    "        \n",
    "        time.sleep(delay)\n",
    "    \n",
    "    # Final statistics\n",
    "    stats = detector.get_statistics()\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 50)\n",
    "    print(\"STREAMING SIMULATION RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total Transactions: {stats['total_transactions']}\")\n",
    "    print(f\"Flagged as Fraud: {stats['total_flagged']}\")\n",
    "    print(f\"Avg Prediction Time: {stats['avg_prediction_time_ms']:.2f}ms\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"  True Positives (Caught Fraud): {true_positives}\")\n",
    "    print(f\"  False Positives (False Alarms): {false_positives}\")\n",
    "    print(f\"  True Negatives (Correct Allow): {true_negatives}\")\n",
    "    print(f\"  False Negatives (Missed Fraud): {false_negatives}\")\n",
    "    \n",
    "    if true_positives + false_negatives > 0:\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "        print(f\"\\nFraud Detection Rate (Recall): {recall:.2%}\")\n",
    "    \n",
    "    return {\n",
    "        'tp': true_positives, 'fp': false_positives,\n",
    "        'tn': true_negatives, 'fn': false_negatives,\n",
    "        'stats': stats\n",
    "    }\n",
    "\n",
    "# Run simulation\n",
    "sim_results = simulate_transaction_stream(detector, X_test, y_test, n_transactions=500, delay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize streaming results\n",
    "history = detector.transaction_history\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Fraud probability over time\n",
    "ax1 = axes[0, 0]\n",
    "probs = [t['fraud_probability'] for t in history]\n",
    "colors = ['red' if t['is_fraud'] else 'green' for t in history]\n",
    "ax1.scatter(range(len(probs)), probs, c=colors, alpha=0.5, s=10)\n",
    "ax1.axhline(y=optimal_threshold, color='blue', linestyle='--', label=f'Threshold ({optimal_threshold:.2f})')\n",
    "ax1.set_xlabel('Transaction #')\n",
    "ax1.set_ylabel('Fraud Probability')\n",
    "ax1.set_title('Fraud Probability Over Time')\n",
    "ax1.legend()\n",
    "\n",
    "# 2. Risk level distribution\n",
    "ax2 = axes[0, 1]\n",
    "risk_counts = pd.Series([t['risk_level'] for t in history]).value_counts()\n",
    "risk_colors = {'LOW': '#2ecc71', 'MEDIUM': '#f1c40f', 'HIGH': '#e67e22', 'CRITICAL': '#e74c3c'}\n",
    "bars = ax2.bar(risk_counts.index, risk_counts.values, \n",
    "               color=[risk_colors.get(r, 'gray') for r in risk_counts.index])\n",
    "ax2.set_xlabel('Risk Level')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title('Risk Level Distribution')\n",
    "\n",
    "# 3. Prediction time distribution\n",
    "ax3 = axes[1, 0]\n",
    "pred_times = [t['prediction_time_ms'] for t in history]\n",
    "ax3.hist(pred_times, bins=30, color='#3498db', edgecolor='black', alpha=0.7)\n",
    "ax3.axvline(x=np.mean(pred_times), color='red', linestyle='--', \n",
    "            label=f'Mean: {np.mean(pred_times):.2f}ms')\n",
    "ax3.set_xlabel('Prediction Time (ms)')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Prediction Latency Distribution')\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Cumulative fraud detection\n",
    "ax4 = axes[1, 1]\n",
    "flagged_cumsum = np.cumsum([1 if t['is_fraud'] else 0 for t in history])\n",
    "ax4.plot(flagged_cumsum, color='red', linewidth=2)\n",
    "ax4.set_xlabel('Transaction #')\n",
    "ax4.set_ylabel('Cumulative Flagged Transactions')\n",
    "ax4.set_title('Cumulative Fraud Flags Over Time')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "### What We Built\n",
    "\n",
    "A complete **Real-Time Fraud Detection System** with:\n",
    "\n",
    "| Component | Implementation |\n",
    "|-----------|---------------|\n",
    "| **Data Handling** | Kaggle credit card dataset |\n",
    "| **Imbalance Handling** | SMOTE, class weights, threshold tuning |\n",
    "| **Models** | Logistic Regression, Random Forest, XGBoost, Neural Network |\n",
    "| **Evaluation** | PR-AUC, ROC-AUC, Confusion Matrix |\n",
    "| **Real-Time Pipeline** | FraudDetector class with streaming simulation |\n",
    "\n",
    "### Key Learnings\n",
    "\n",
    "1. **Class Imbalance**: Don't use accuracy! Use PR-AUC and recall\n",
    "2. **Threshold Tuning**: Default 0.5 is rarely optimal for fraud\n",
    "3. **Business Costs**: Different costs for FN vs FP\n",
    "4. **Real-Time Requirements**: Sub-millisecond predictions possible\n",
    "\n",
    "### Best Practices for Fraud Detection\n",
    "\n",
    "1. Always use stratified sampling\n",
    "2. Focus on recall (catch frauds) over precision\n",
    "3. Consider business costs when setting thresholds\n",
    "4. Monitor model performance over time (fraud patterns change!)\n",
    "5. Use ensemble methods for robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\"*60)\n",
    "print(\"REAL-TIME FRAUD DETECTION SYSTEM - FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Dataset:\n",
    "────────\n",
    "  - {len(df):,} credit card transactions\n",
    "  - {(df['Class']==1).sum()} frauds ({(df['Class']==1).mean()*100:.3f}%)\n",
    "  - 30 features (V1-V28 + Amount + Time)\n",
    "\n",
    "Best Model: {best_model_name}\n",
    "────────────────────────────────\n",
    "  - ROC-AUC: {results[best_model_name]['roc_auc']:.4f}\n",
    "  - PR-AUC:  {results[best_model_name]['pr_auc']:.4f}\n",
    "  - Optimal Threshold: {optimal_threshold:.2f}\n",
    "\n",
    "Real-Time Performance:\n",
    "─────────────────────\n",
    "  - Avg Prediction Time: {detector.get_statistics()['avg_prediction_time_ms']:.2f}ms\n",
    "  - Throughput: ~{1000/max(0.01, detector.get_statistics()['avg_prediction_time_ms']):.0f} transactions/second\n",
    "\n",
    "Techniques Used:\n",
    "───────────────\n",
    "  - SMOTE for oversampling\n",
    "  - Class weights for imbalance\n",
    "  - Threshold optimization\n",
    "  - Business cost analysis\n",
    "  - Streaming simulation\n",
    "\n",
    "Key Metrics for Fraud Detection:\n",
    "────────────────────────────────\n",
    "  - Recall (Sensitivity): Catch as many frauds as possible\n",
    "  - PR-AUC: Better than ROC-AUC for imbalanced data\n",
    "  - False Negative Cost: Most important to minimize\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
