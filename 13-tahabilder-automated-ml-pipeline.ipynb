{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML Pipeline - Complete Tutorial\n",
    "\n",
    "**Author:** Anik Tahabilder  \n",
    "**Project:** 13 of 22 - Kaggle ML Portfolio  \n",
    "**Difficulty:** 7/10 | **Learning Value:** 9/10\n",
    "\n",
    "---\n",
    "\n",
    "## What Will You Learn?\n",
    "\n",
    "This tutorial teaches **how to automate the entire ML workflow**.\n",
    "\n",
    "| Topic | What You'll Understand |\n",
    "|-------|------------------------|\n",
    "| **ML Pipeline Concept** | Why pipelines matter for production |\n",
    "| **Automated Preprocessing** | Handle missing values, scaling, encoding automatically |\n",
    "| **Feature Selection** | Filter, Wrapper, Embedded methods |\n",
    "| **Model Selection** | Compare multiple models automatically |\n",
    "| **Hyperparameter Tuning** | Grid Search, Random Search, Bayesian Optimization |\n",
    "| **Cross-Validation** | K-Fold, Stratified, Time Series splits |\n",
    "| **Complete AutoML** | End-to-end automated pipeline |\n",
    "\n",
    "---\n",
    "\n",
    "## The AutoML Pipeline\n",
    "\n",
    "```\n",
    "┌──────────────────────────────────────────────────────────────────────────┐\n",
    "│                        AUTOMATED ML PIPELINE                              │\n",
    "├──────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                          │\n",
    "│   ┌─────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐  │\n",
    "│   │  Data   │───>│Preprocessing│───>│  Feature    │───>│   Model     │  │\n",
    "│   │         │    │             │    │  Selection  │    │  Selection  │  │\n",
    "│   └─────────┘    └─────────────┘    └─────────────┘    └──────┬──────┘  │\n",
    "│                                                               │         │\n",
    "│   ┌─────────────────────────────────────────────────────────┘         │\n",
    "│   │                                                                     │\n",
    "│   v                                                                     │\n",
    "│   ┌─────────────┐    ┌─────────────┐    ┌─────────────┐                │\n",
    "│   │Hyperparameter│───>│ Evaluation  │───>│ Deployment  │                │\n",
    "│   │   Tuning    │    │             │    │             │                │\n",
    "│   └─────────────┘    └─────────────┘    └─────────────┘                │\n",
    "│                                                                          │\n",
    "└──────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Part 1: Why AutoML Pipelines?](#part1)\n",
    "2. [Part 2: Automated Preprocessing](#part2)\n",
    "3. [Part 3: Feature Selection Methods](#part3)\n",
    "4. [Part 4: Automated Model Selection](#part4)\n",
    "5. [Part 5: Hyperparameter Tuning](#part5)\n",
    "6. [Part 6: Cross-Validation Strategies](#part6)\n",
    "7. [Part 7: Complete AutoML Pipeline](#part7)\n",
    "8. [Part 8: Evaluation & Results](#part8)\n",
    "9. [Part 9: Summary & Best Practices](#part9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part1'></a>\n",
    "# Part 1: Why AutoML Pipelines?\n",
    "\n",
    "---\n",
    "\n",
    "## 1.1 The Problem with Manual ML\n",
    "\n",
    "| Manual Approach | Problems |\n",
    "|-----------------|----------|\n",
    "| Separate preprocessing | Data leakage risk |\n",
    "| Manual feature selection | Time-consuming, biased |\n",
    "| Try models one by one | Inefficient, miss best model |\n",
    "| Hand-tune hyperparameters | Suboptimal, not reproducible |\n",
    "\n",
    "## 1.2 Benefits of Pipelines\n",
    "\n",
    "| Benefit | Description |\n",
    "|---------|-------------|\n",
    "| **No Data Leakage** | Preprocessing fitted only on training data |\n",
    "| **Reproducibility** | Same pipeline = same results |\n",
    "| **Easy Deployment** | Single object to save/load |\n",
    "| **Automation** | Less manual work, fewer errors |\n",
    "| **Scalability** | Easy to add new steps |\n",
    "\n",
    "## 1.3 Pipeline Components\n",
    "\n",
    "```\n",
    "sklearn.pipeline.Pipeline\n",
    "│\n",
    "├── Step 1: Preprocessor (ColumnTransformer)\n",
    "│   ├── Numeric: Imputer → Scaler\n",
    "│   └── Categorical: Imputer → Encoder\n",
    "│\n",
    "├── Step 2: Feature Selection (optional)\n",
    "│   └── SelectKBest, RFE, etc.\n",
    "│\n",
    "└── Step 3: Model\n",
    "    └── Any sklearn estimator\n",
    "```\n",
    "\n",
    "## 1.4 Key Sklearn Classes\n",
    "\n",
    "| Class | Purpose |\n",
    "|-------|--------|\n",
    "| `Pipeline` | Chain transformers + estimator |\n",
    "| `ColumnTransformer` | Apply different transforms to columns |\n",
    "| `GridSearchCV` | Exhaustive hyperparameter search |\n",
    "| `RandomizedSearchCV` | Random hyperparameter search |\n",
    "| `cross_val_score` | Cross-validation scoring |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP AND IMPORTS\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn - Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Sklearn - Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.feature_selection import RFE, RFECV, SelectFromModel\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Sklearn - Models\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Sklearn - Pipeline & Model Selection\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, TimeSeriesSplit\n",
    "\n",
    "# Sklearn - Metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Display settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"AUTOMATED ML PIPELINE - TUTORIAL\")\n",
    "print(\"=\"*70)\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(\"\\nAll libraries loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ============================================================\n# LOAD TITANIC DATASET\n# ============================================================\nprint(\"=\"*70)\nprint(\"LOADING TITANIC DATASET\")\nprint(\"=\"*70)\n\n# ============================================================\n# KAGGLE PATH CONFIGURATION\n# ============================================================\n# Dataset: https://www.kaggle.com/competitions/titanic\n# Path: /kaggle/input/titanic\n\nUSE_KAGGLE = os.path.exists('/kaggle/input')\n\nif USE_KAGGLE:\n    TRAIN_PATH = '/kaggle/input/titanic/train.csv'\n    TEST_PATH = '/kaggle/input/titanic/test.csv'\n    \n    if os.path.exists(TRAIN_PATH):\n        df = pd.read_csv(TRAIN_PATH)\n        print(f\"✓ Loaded from: {TRAIN_PATH}\")\n    else:\n        print(\"Titanic dataset not found!\")\n        print(\"Add the 'titanic' competition dataset in Kaggle\")\n        df = None\nelse:\n    df = None\n\n# Fallback: Create Titanic-like synthetic data\nif df is None:\n    print(\"\\nCreating Titanic-like synthetic dataset...\")\n    print(\"(Add 'titanic' dataset in Kaggle for real data)\")\n    \n    np.random.seed(42)\n    n_samples = 891  # Same as real Titanic\n    \n    df = pd.DataFrame({\n        'PassengerId': range(1, n_samples + 1),\n        'Pclass': np.random.choice([1, 2, 3], n_samples, p=[0.24, 0.21, 0.55]),\n        'Name': [f'Passenger_{i}' for i in range(n_samples)],\n        'Sex': np.random.choice(['male', 'female'], n_samples, p=[0.65, 0.35]),\n        'Age': np.random.normal(30, 14, n_samples).clip(1, 80),\n        'SibSp': np.random.choice([0, 1, 2, 3, 4], n_samples, p=[0.68, 0.23, 0.05, 0.02, 0.02]),\n        'Parch': np.random.choice([0, 1, 2, 3], n_samples, p=[0.76, 0.13, 0.09, 0.02]),\n        'Ticket': [f'T{np.random.randint(10000, 99999)}' for _ in range(n_samples)],\n        'Fare': np.random.exponential(32, n_samples).clip(0, 512),\n        'Cabin': np.random.choice(['C85', 'B42', 'E101', np.nan], n_samples, p=[0.05, 0.05, 0.05, 0.85]),\n        'Embarked': np.random.choice(['S', 'C', 'Q', np.nan], n_samples, p=[0.70, 0.19, 0.09, 0.02]),\n    })\n    \n    # Create realistic Survived target\n    survival_prob = (\n        0.2 +\n        0.3 * (df['Sex'] == 'female').astype(int) +\n        0.2 * (df['Pclass'] == 1).astype(int) +\n        0.1 * (df['Pclass'] == 2).astype(int) +\n        -0.1 * (df['Age'] > 50).astype(int) +\n        np.random.randn(n_samples) * 0.1\n    ).clip(0, 1)\n    df['Survived'] = (survival_prob > 0.5).astype(int)\n    \n    # Add missing values like real Titanic\n    age_missing = np.random.random(n_samples) < 0.2\n    df.loc[age_missing, 'Age'] = np.nan\n\ntarget_col = 'Survived'\n\nprint(f\"\\n\" + \"=\"*50)\nprint(\"TITANIC DATASET SUMMARY\")\nprint(\"=\"*50)\nprint(f\"Shape: {df.shape}\")\nprint(f\"Target: {target_col}\")\nprint(f\"\\nSurvival Distribution:\")\nprint(df[target_col].value_counts())\nprint(f\"  Survival Rate: {df[target_col].mean()*100:.1f}%\")\n\nprint(f\"\\nMissing Values:\")\nmissing = df.isnull().sum()\nprint(missing[missing > 0])\n\nprint(f\"\\nColumn Types:\")\nprint(df.dtypes)\n\nprint(f\"\\nFirst few rows:\")\ndf.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CREATE PREPROCESSING PIPELINE\n# ============================================================\nprint(\"=\"*70)\nprint(\"AUTOMATED PREPROCESSING PIPELINE\")\nprint(\"=\"*70)\n\n# ============================================================\n# TITANIC FEATURE ENGINEERING\n# ============================================================\n# Drop columns that are not useful for prediction:\n# - PassengerId: Just an identifier\n# - Name: Text field (could extract titles but keeping it simple)\n# - Ticket: Mostly unique values\n# - Cabin: 77% missing values\n\ndrop_cols = ['PassengerId', 'Name', 'Ticket', 'Cabin']\ndf_clean = df.drop(columns=[col for col in drop_cols if col in df.columns])\n\nprint(\"Dropped columns (not useful for prediction):\")\nfor col in drop_cols:\n    if col in df.columns:\n        print(f\"  - {col}\")\n\n# Separate features and target\nX = df_clean.drop(columns=[target_col])\ny = df_clean[target_col]\n\n# Encode target if needed\nif y.dtype == 'object':\n    le = LabelEncoder()\n    y = le.fit_transform(y)\n\n# Identify column types\nnumeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\ncategorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n\nprint(f\"\\nFeatures for modeling:\")\nprint(f\"  Numeric ({len(numeric_cols)}): {numeric_cols}\")\nprint(f\"  Categorical ({len(categorical_cols)}): {categorical_cols}\")\n\n# Create preprocessing pipelines\nnumeric_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n# Combine with ColumnTransformer\npreprocessor = ColumnTransformer([\n    ('numeric', numeric_pipeline, numeric_cols),\n    ('categorical', categorical_pipeline, categorical_cols)\n], remainder='drop')\n\nprint(\"\\nPreprocessor Pipeline:\")\nprint(\"\"\"\nColumnTransformer\n├── Numeric Pipeline (Pclass, Age, SibSp, Parch, Fare):\n│   ├── SimpleImputer(strategy='median')  # Handle missing Age\n│   └── StandardScaler()                  # Normalize features\n│\n└── Categorical Pipeline (Sex, Embarked):\n    ├── SimpleImputer(strategy='most_frequent')  # Handle missing Embarked\n    └── OneHotEncoder(handle_unknown='ignore')   # Create dummy variables\n\"\"\")\n\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(f\"\\nData Split:\")\nprint(f\"  Train size: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\nprint(f\"  Test size: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n\n# Fit and transform\nX_train_processed = preprocessor.fit_transform(X_train)\nX_test_processed = preprocessor.transform(X_test)\n\nprint(f\"\\nProcessed feature shape: {X_train_processed.shape}\")\nprint(f\"  Original features: {X.shape[1]}\")\nprint(f\"  After encoding: {X_train_processed.shape[1]} (due to one-hot encoding)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part3'></a>\n",
    "# Part 3: Feature Selection Methods\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 Three Categories of Feature Selection\n",
    "\n",
    "| Category | Method | How It Works | Speed |\n",
    "|----------|--------|--------------|-------|\n",
    "| **Filter** | SelectKBest, VarianceThreshold | Statistical tests, independent of model | Fast |\n",
    "| **Wrapper** | RFE, RFECV | Uses model performance | Slow |\n",
    "| **Embedded** | SelectFromModel (L1, RF) | Built into model training | Medium |\n",
    "\n",
    "## 3.2 Filter Methods\n",
    "\n",
    "| Method | For | Description |\n",
    "|--------|-----|-------------|\n",
    "| **VarianceThreshold** | All | Remove low-variance features |\n",
    "| **SelectKBest + f_classif** | Classification | ANOVA F-test |\n",
    "| **SelectKBest + mutual_info** | Classification | Information gain |\n",
    "| **SelectKBest + f_regression** | Regression | Correlation-based |\n",
    "\n",
    "## 3.3 Wrapper Methods\n",
    "\n",
    "| Method | Description | Use When |\n",
    "|--------|-------------|----------|\n",
    "| **RFE** | Recursive feature elimination | Know target # features |\n",
    "| **RFECV** | RFE with cross-validation | Want optimal # features |\n",
    "\n",
    "## 3.4 Embedded Methods\n",
    "\n",
    "| Method | Description | Use When |\n",
    "|--------|-------------|----------|\n",
    "| **L1 (Lasso)** | Coefficients shrink to zero | Linear models |\n",
    "| **Tree Feature Importance** | Based on split quality | Tree-based models |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FEATURE SELECTION METHODS\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURE SELECTION METHODS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Store results for comparison\n",
    "feature_selection_results = []\n",
    "\n",
    "# 1. FILTER METHOD: SelectKBest\n",
    "print(\"\\n1. FILTER METHOD: SelectKBest (ANOVA F-test)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "selector_kbest = SelectKBest(score_func=f_classif, k='all')\n",
    "selector_kbest.fit(X_train_processed, y_train)\n",
    "\n",
    "# Get scores\n",
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': range(X_train_processed.shape[1]),\n",
    "    'F_Score': selector_kbest.scores_,\n",
    "    'P_Value': selector_kbest.pvalues_\n",
    "}).sort_values('F_Score', ascending=False)\n",
    "\n",
    "print(f\"Top 10 features by F-score:\")\n",
    "print(feature_scores.head(10).to_string(index=False))\n",
    "\n",
    "# 2. FILTER METHOD: Mutual Information\n",
    "print(\"\\n2. FILTER METHOD: Mutual Information\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "mi_scores = mutual_info_classif(X_train_processed, y_train, random_state=42)\n",
    "mi_df = pd.DataFrame({\n",
    "    'Feature': range(len(mi_scores)),\n",
    "    'MI_Score': mi_scores\n",
    "}).sort_values('MI_Score', ascending=False)\n",
    "\n",
    "print(f\"Top 10 features by Mutual Information:\")\n",
    "print(mi_df.head(10).to_string(index=False))\n",
    "\n",
    "# 3. WRAPPER METHOD: RFE\n",
    "print(\"\\n3. WRAPPER METHOD: Recursive Feature Elimination (RFE)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "base_model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "rfe = RFE(estimator=base_model, n_features_to_select=10, step=1)\n",
    "rfe.fit(X_train_processed, y_train)\n",
    "\n",
    "rfe_selected = np.where(rfe.support_)[0]\n",
    "print(f\"Selected {len(rfe_selected)} features: {rfe_selected.tolist()}\")\n",
    "\n",
    "# 4. EMBEDDED METHOD: Feature Importance\n",
    "print(\"\\n4. EMBEDDED METHOD: Random Forest Feature Importance\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "rf_for_importance = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_for_importance.fit(X_train_processed, y_train)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': range(len(rf_for_importance.feature_importances_)),\n",
    "    'Importance': rf_for_importance.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"Top 10 features by Random Forest Importance:\")\n",
    "print(importance_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE VISUALIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# F-scores\n",
    "ax1 = axes[0]\n",
    "top_f = feature_scores.head(15)\n",
    "ax1.barh(range(len(top_f)), top_f['F_Score'], color='steelblue')\n",
    "ax1.set_yticks(range(len(top_f)))\n",
    "ax1.set_yticklabels([f\"Feature {i}\" for i in top_f['Feature']])\n",
    "ax1.set_xlabel('F-Score')\n",
    "ax1.set_title('ANOVA F-Test Scores', fontweight='bold')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Mutual Information\n",
    "ax2 = axes[1]\n",
    "top_mi = mi_df.head(15)\n",
    "ax2.barh(range(len(top_mi)), top_mi['MI_Score'], color='coral')\n",
    "ax2.set_yticks(range(len(top_mi)))\n",
    "ax2.set_yticklabels([f\"Feature {i}\" for i in top_mi['Feature']])\n",
    "ax2.set_xlabel('Mutual Information')\n",
    "ax2.set_title('Mutual Information Scores', fontweight='bold')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "# Random Forest Importance\n",
    "ax3 = axes[2]\n",
    "top_rf = importance_df.head(15)\n",
    "ax3.barh(range(len(top_rf)), top_rf['Importance'], color='green')\n",
    "ax3.set_yticks(range(len(top_rf)))\n",
    "ax3.set_yticklabels([f\"Feature {i}\" for i in top_rf['Feature']])\n",
    "ax3.set_xlabel('Importance')\n",
    "ax3.set_title('Random Forest Importance', fontweight='bold')\n",
    "ax3.invert_yaxis()\n",
    "\n",
    "plt.suptitle('Feature Selection Method Comparison', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part4'></a>\n",
    "# Part 4: Automated Model Selection\n",
    "\n",
    "---\n",
    "\n",
    "## 4.1 Comparing Multiple Models\n",
    "\n",
    "| Model Family | Models | Best For |\n",
    "|--------------|--------|----------|\n",
    "| **Linear** | LogisticRegression, SVC(linear) | Linearly separable, interpretable |\n",
    "| **Tree-based** | DecisionTree, RandomForest, GradientBoosting | Non-linear, feature importance |\n",
    "| **Distance-based** | KNN, SVC(rbf) | Non-linear, small datasets |\n",
    "| **Probabilistic** | GaussianNB | Fast, baseline |\n",
    "| **Neural** | MLPClassifier | Complex patterns, lots of data |\n",
    "\n",
    "## 4.2 Model Selection Strategy\n",
    "\n",
    "```\n",
    "1. Start with diverse set of models\n",
    "2. Use cross-validation for fair comparison\n",
    "3. Select top N models for hyperparameter tuning\n",
    "4. Final evaluation on holdout test set\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AUTOMATED MODEL SELECTION\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"AUTOMATED MODEL SELECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define models to compare\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', random_state=42, probability=True),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42),\n",
    "}\n",
    "\n",
    "print(f\"\\nComparing {len(models)} models with 5-fold cross-validation...\")\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "# Compare models\n",
    "results = []\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_processed, y_train, cv=cv, scoring='accuracy')\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'CV Mean': cv_scores.mean(),\n",
    "        'CV Std': cv_scores.std(),\n",
    "        'Time (s)': elapsed\n",
    "    })\n",
    "    \n",
    "    print(f\"{name:25s} | Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f}) | {elapsed:.2f}s\")\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values('CV Mean', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL RANKING\")\n",
    "print(\"=\"*60)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL COMPARISON VISUALIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "ax1 = axes[0]\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(results_df)))\n",
    "bars = ax1.barh(results_df['Model'], results_df['CV Mean'], \n",
    "                xerr=results_df['CV Std'], color=colors, edgecolor='black')\n",
    "ax1.set_xlabel('Cross-Validation Accuracy')\n",
    "ax1.set_title('Model Accuracy Comparison', fontweight='bold')\n",
    "ax1.axvline(x=results_df['CV Mean'].max(), color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add values\n",
    "for bar, val in zip(bars, results_df['CV Mean']):\n",
    "    ax1.text(val + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "             f'{val:.3f}', va='center', fontsize=9)\n",
    "\n",
    "# Speed vs Accuracy\n",
    "ax2 = axes[1]\n",
    "scatter = ax2.scatter(results_df['Time (s)'], results_df['CV Mean'], \n",
    "                      s=100, c=range(len(results_df)), cmap='viridis', edgecolor='black')\n",
    "for i, row in results_df.iterrows():\n",
    "    ax2.annotate(row['Model'], (row['Time (s)'], row['CV Mean']), \n",
    "                 fontsize=8, ha='left', va='bottom')\n",
    "ax2.set_xlabel('Training Time (seconds)')\n",
    "ax2.set_ylabel('CV Accuracy')\n",
    "ax2.set_title('Speed vs Accuracy Trade-off', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Select top 3 models for hyperparameter tuning\n",
    "top_models = results_df.head(3)['Model'].tolist()\n",
    "print(f\"\\nTop 3 models for hyperparameter tuning: {top_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part5'></a>\n",
    "# Part 5: Hyperparameter Tuning\n",
    "\n",
    "---\n",
    "\n",
    "## 5.1 Tuning Methods Comparison\n",
    "\n",
    "| Method | How It Works | Pros | Cons |\n",
    "|--------|--------------|------|------|\n",
    "| **Grid Search** | Try all combinations | Thorough | Slow, curse of dimensionality |\n",
    "| **Random Search** | Random combinations | Faster, often as good | May miss optimal |\n",
    "| **Bayesian Optimization** | Learn from previous trials | Efficient | More complex |\n",
    "| **Halving Search** | Progressive filtering | Very fast | May discard good candidates |\n",
    "\n",
    "## 5.2 When to Use Which?\n",
    "\n",
    "| Scenario | Recommended Method |\n",
    "|----------|-------------------|\n",
    "| Few hyperparameters (2-3) | Grid Search |\n",
    "| Many hyperparameters (4+) | Random Search |\n",
    "| Limited compute budget | Random Search or Halving |\n",
    "| Expensive evaluations | Bayesian Optimization |\n",
    "| Quick baseline | Random Search (n_iter=20) |\n",
    "\n",
    "## 5.3 Common Hyperparameters\n",
    "\n",
    "| Model | Key Hyperparameters |\n",
    "|-------|--------------------|\n",
    "| **Random Forest** | n_estimators, max_depth, min_samples_split, max_features |\n",
    "| **Gradient Boosting** | n_estimators, learning_rate, max_depth, subsample |\n",
    "| **SVM** | C, kernel, gamma |\n",
    "| **KNN** | n_neighbors, weights, metric |\n",
    "| **MLP** | hidden_layer_sizes, learning_rate, alpha |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# HYPERPARAMETER TUNING\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define parameter grids for top models\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    },\n",
    "    'Extra Trees': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "}\n",
    "\n",
    "# 1. Grid Search Example\n",
    "print(\"\\n1. GRID SEARCH\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use smaller grid for demonstration\n",
    "small_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_grid=small_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "grid_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nGrid Search completed in {grid_time:.2f}s\")\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "print(f\"Total combinations tried: {len(grid_search.cv_results_['params'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Random Search\n",
    "print(\"\\n2. RANDOM SEARCH\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "random_grid = {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'max_depth': [5, 10, 20, 30, None],\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_distributions=random_grid,\n",
    "    n_iter=20,  # Number of random combinations\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train_processed, y_train)\n",
    "random_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nRandom Search completed in {random_time:.2f}s\")\n",
    "print(f\"Best params: {random_search.best_params_}\")\n",
    "print(f\"Best CV score: {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Compare Grid vs Random\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GRID SEARCH vs RANDOM SEARCH\")\n",
    "print(\"=\"*50)\n",
    "comparison = pd.DataFrame({\n",
    "    'Method': ['Grid Search', 'Random Search'],\n",
    "    'Best Score': [grid_search.best_score_, random_search.best_score_],\n",
    "    'Time (s)': [grid_time, random_time],\n",
    "    'Combinations': [len(grid_search.cv_results_['params']), 20]\n",
    "})\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize hyperparameter search results\n",
    "print(\"=\"*70)\n",
    "print(\"HYPERPARAMETER SEARCH VISUALIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get random search results\n",
    "cv_results = pd.DataFrame(random_search.cv_results_)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Score vs n_estimators\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(cv_results['param_n_estimators'], cv_results['mean_test_score'], \n",
    "           c=cv_results['mean_test_score'], cmap='viridis', s=100, edgecolor='black')\n",
    "ax1.set_xlabel('n_estimators')\n",
    "ax1.set_ylabel('Mean CV Score')\n",
    "ax1.set_title('Score vs n_estimators', fontweight='bold')\n",
    "\n",
    "# Score distribution\n",
    "ax2 = axes[1]\n",
    "ax2.hist(cv_results['mean_test_score'], bins=10, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=random_search.best_score_, color='red', linestyle='--', \n",
    "           label=f'Best: {random_search.best_score_:.4f}')\n",
    "ax2.set_xlabel('Mean CV Score')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Score Distribution Across Trials', fontweight='bold')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part6'></a>\n",
    "# Part 6: Cross-Validation Strategies\n",
    "\n",
    "---\n",
    "\n",
    "## 6.1 Types of Cross-Validation\n",
    "\n",
    "| Method | Use Case | Maintains Class Balance |\n",
    "|--------|----------|------------------------|\n",
    "| **KFold** | Regression, balanced classification | No |\n",
    "| **StratifiedKFold** | Imbalanced classification | Yes |\n",
    "| **TimeSeriesSplit** | Time series data | N/A (respects time) |\n",
    "| **LeaveOneOut** | Very small datasets | No |\n",
    "| **GroupKFold** | Grouped data (avoid leakage) | No |\n",
    "\n",
    "## 6.2 Choosing the Right CV Strategy\n",
    "\n",
    "| Data Type | Recommended CV |\n",
    "|-----------|---------------|\n",
    "| **Classification (balanced)** | KFold or StratifiedKFold |\n",
    "| **Classification (imbalanced)** | StratifiedKFold |\n",
    "| **Regression** | KFold |\n",
    "| **Time series** | TimeSeriesSplit |\n",
    "| **Grouped data** | GroupKFold |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CROSS-VALIDATION STRATEGIES\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"CROSS-VALIDATION STRATEGIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Define CV strategies\n",
    "cv_strategies = {\n",
    "    'KFold (5)': KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    'StratifiedKFold (5)': StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    'KFold (10)': KFold(n_splits=10, shuffle=True, random_state=42),\n",
    "    'StratifiedKFold (10)': StratifiedKFold(n_splits=10, shuffle=True, random_state=42),\n",
    "}\n",
    "\n",
    "# Use best model from previous search\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "cv_results = []\n",
    "for name, cv_strategy in cv_strategies.items():\n",
    "    scores = cross_val_score(best_model, X_train_processed, y_train, \n",
    "                             cv=cv_strategy, scoring='accuracy')\n",
    "    cv_results.append({\n",
    "        'CV Strategy': name,\n",
    "        'Mean': scores.mean(),\n",
    "        'Std': scores.std(),\n",
    "        'Min': scores.min(),\n",
    "        'Max': scores.max()\n",
    "    })\n",
    "    print(f\"{name:25s} | Mean: {scores.mean():.4f} | Std: {scores.std():.4f}\")\n",
    "\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CV STRATEGY COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(cv_results_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"  - More folds = lower variance, higher compute\")\n",
    "print(\"  - StratifiedKFold recommended for classification\")\n",
    "print(\"  - 5-fold is good default, 10-fold for more reliable estimate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part7'></a>\n",
    "# Part 7: Complete AutoML Pipeline\n",
    "\n",
    "---\n",
    "\n",
    "## 7.1 Putting It All Together\n",
    "\n",
    "Now we build a complete automated pipeline that:\n",
    "1. Preprocesses data automatically\n",
    "2. Selects best features\n",
    "3. Tunes hyperparameters\n",
    "4. Returns best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COMPLETE AUTOML PIPELINE CLASS\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"COMPLETE AUTOML PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class AutoMLPipeline:\n",
    "    \"\"\"\n",
    "    Automated Machine Learning Pipeline.\n",
    "    \n",
    "    Automates:\n",
    "    1. Preprocessing (imputation, scaling, encoding)\n",
    "    2. Feature selection\n",
    "    3. Model selection\n",
    "    4. Hyperparameter tuning\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task='classification', n_jobs=-1, random_state=42):\n",
    "        self.task = task\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "        self.preprocessor = None\n",
    "        self.best_pipeline = None\n",
    "        self.best_model_name = None\n",
    "        self.best_params = None\n",
    "        self.best_score = None\n",
    "        self.model_results = None\n",
    "        \n",
    "    def _get_models(self):\n",
    "        \"\"\"Return dictionary of models to try.\"\"\"\n",
    "        if self.task == 'classification':\n",
    "            return {\n",
    "                'LogisticRegression': LogisticRegression(max_iter=1000, random_state=self.random_state),\n",
    "                'RandomForest': RandomForestClassifier(random_state=self.random_state, n_jobs=self.n_jobs),\n",
    "                'GradientBoosting': GradientBoostingClassifier(random_state=self.random_state),\n",
    "                'ExtraTrees': ExtraTreesClassifier(random_state=self.random_state, n_jobs=self.n_jobs),\n",
    "                'SVM': SVC(random_state=self.random_state, probability=True),\n",
    "            }\n",
    "        else:\n",
    "            from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "            from sklearn.linear_model import Ridge, Lasso\n",
    "            return {\n",
    "                'Ridge': Ridge(random_state=self.random_state),\n",
    "                'Lasso': Lasso(random_state=self.random_state),\n",
    "                'RandomForest': RandomForestRegressor(random_state=self.random_state, n_jobs=self.n_jobs),\n",
    "                'GradientBoosting': GradientBoostingRegressor(random_state=self.random_state),\n",
    "            }\n",
    "    \n",
    "    def _get_param_grids(self):\n",
    "        \"\"\"Return hyperparameter grids for each model.\"\"\"\n",
    "        return {\n",
    "            'LogisticRegression': {\n",
    "                'model__C': [0.01, 0.1, 1, 10],\n",
    "                'model__penalty': ['l1', 'l2'],\n",
    "                'model__solver': ['liblinear', 'saga']\n",
    "            },\n",
    "            'RandomForest': {\n",
    "                'model__n_estimators': [50, 100, 200],\n",
    "                'model__max_depth': [5, 10, None],\n",
    "                'model__min_samples_split': [2, 5]\n",
    "            },\n",
    "            'GradientBoosting': {\n",
    "                'model__n_estimators': [50, 100],\n",
    "                'model__learning_rate': [0.05, 0.1, 0.2],\n",
    "                'model__max_depth': [3, 5]\n",
    "            },\n",
    "            'ExtraTrees': {\n",
    "                'model__n_estimators': [50, 100, 200],\n",
    "                'model__max_depth': [5, 10, None]\n",
    "            },\n",
    "            'SVM': {\n",
    "                'model__C': [0.1, 1, 10],\n",
    "                'model__kernel': ['rbf', 'linear']\n",
    "            },\n",
    "            'Ridge': {\n",
    "                'model__alpha': [0.1, 1, 10, 100]\n",
    "            },\n",
    "            'Lasso': {\n",
    "                'model__alpha': [0.001, 0.01, 0.1, 1]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _create_preprocessor(self, X):\n",
    "        \"\"\"Create preprocessing pipeline based on data types.\"\"\"\n",
    "        numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        \n",
    "        numeric_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        \n",
    "        categorical_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ])\n",
    "        \n",
    "        preprocessor = ColumnTransformer([\n",
    "            ('numeric', numeric_pipeline, numeric_cols),\n",
    "            ('categorical', categorical_pipeline, categorical_cols)\n",
    "        ], remainder='drop')\n",
    "        \n",
    "        return preprocessor\n",
    "    \n",
    "    def fit(self, X, y, cv=5, scoring=None, verbose=True):\n",
    "        \"\"\"\n",
    "        Fit the AutoML pipeline.\n",
    "        \n",
    "        Parameters:\n",
    "        - X: Features (DataFrame)\n",
    "        - y: Target\n",
    "        - cv: Cross-validation folds\n",
    "        - scoring: Scoring metric\n",
    "        - verbose: Print progress\n",
    "        \"\"\"\n",
    "        if scoring is None:\n",
    "            scoring = 'accuracy' if self.task == 'classification' else 'neg_mean_squared_error'\n",
    "        \n",
    "        # Create preprocessor\n",
    "        self.preprocessor = self._create_preprocessor(X)\n",
    "        \n",
    "        # Get models and param grids\n",
    "        models = self._get_models()\n",
    "        param_grids = self._get_param_grids()\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nAutoML: Testing {len(models)} models...\")\n",
    "            print(\"-\" * 60)\n",
    "        \n",
    "        # Compare all models\n",
    "        results = []\n",
    "        best_score = -np.inf\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            # Create pipeline\n",
    "            pipeline = Pipeline([\n",
    "                ('preprocessor', self.preprocessor),\n",
    "                ('model', model)\n",
    "            ])\n",
    "            \n",
    "            # Get param grid\n",
    "            param_grid = param_grids.get(name, {})\n",
    "            \n",
    "            # Hyperparameter tuning\n",
    "            if param_grid:\n",
    "                search = RandomizedSearchCV(\n",
    "                    pipeline, param_grid, \n",
    "                    n_iter=10, cv=cv, scoring=scoring,\n",
    "                    n_jobs=self.n_jobs, random_state=self.random_state\n",
    "                )\n",
    "            else:\n",
    "                search = GridSearchCV(\n",
    "                    pipeline, {}, cv=cv, scoring=scoring\n",
    "                )\n",
    "            \n",
    "            search.fit(X, y)\n",
    "            \n",
    "            results.append({\n",
    "                'Model': name,\n",
    "                'Best Score': search.best_score_,\n",
    "                'Best Params': search.best_params_\n",
    "            })\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"{name:20s} | Score: {search.best_score_:.4f}\")\n",
    "            \n",
    "            # Track best\n",
    "            if search.best_score_ > best_score:\n",
    "                best_score = search.best_score_\n",
    "                self.best_pipeline = search.best_estimator_\n",
    "                self.best_model_name = name\n",
    "                self.best_params = search.best_params_\n",
    "                self.best_score = search.best_score_\n",
    "        \n",
    "        self.model_results = pd.DataFrame(results).sort_values('Best Score', ascending=False)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(f\"BEST MODEL: {self.best_model_name}\")\n",
    "            print(f\"BEST SCORE: {self.best_score:.4f}\")\n",
    "            print(f\"BEST PARAMS: {self.best_params}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using best pipeline.\"\"\"\n",
    "        return self.best_pipeline.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Get probability predictions.\"\"\"\n",
    "        return self.best_pipeline.predict_proba(X)\n",
    "    \n",
    "    def get_results(self):\n",
    "        \"\"\"Return model comparison results.\"\"\"\n",
    "        return self.model_results\n",
    "\n",
    "print(\"\\nAutoMLPipeline class created!\")\n",
    "print(\"\\nFeatures:\")\n",
    "print(\"  - Automatic preprocessing\")\n",
    "print(\"  - Multiple model comparison\")\n",
    "print(\"  - Hyperparameter tuning\")\n",
    "print(\"  - Best model selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RUN AUTOML PIPELINE\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"RUNNING AUTOML PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize AutoML\n",
    "automl = AutoMLPipeline(task='classification', n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit on training data\n",
    "start_time = time.time()\n",
    "automl.fit(X_train, y_train, cv=5, scoring='accuracy', verbose=True)\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nTotal AutoML time: {total_time:.2f} seconds\")\n",
    "\n",
    "# Show all results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ALL MODEL RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(automl.get_results().to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part8'></a>\n",
    "# Part 8: Evaluation & Results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FINAL EVALUATION ON TEST SET\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL EVALUATION ON TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = automl.predict(X_test)\n",
    "y_proba = automl.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "print(f\"\\nBest Model: {automl.best_model_name}\")\n",
    "print(f\"\\nTest Set Metrics:\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  F1 Score:  {f1:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  ROC-AUC:   {roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "print(\"=\"*70)\n",
    "print(\"RESULTS VISUALIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay, ConfusionMatrixDisplay\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "ax1 = axes[0]\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=ax1, cmap='Blues')\n",
    "ax1.set_title('Confusion Matrix', fontweight='bold')\n",
    "\n",
    "# ROC Curve\n",
    "ax2 = axes[1]\n",
    "RocCurveDisplay.from_predictions(y_test, y_proba, ax=ax2)\n",
    "ax2.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax2.set_title(f'ROC Curve (AUC = {roc_auc:.3f})', fontweight='bold')\n",
    "ax2.legend()\n",
    "\n",
    "# Model Comparison\n",
    "ax3 = axes[2]\n",
    "model_results = automl.get_results()\n",
    "colors = ['green' if m == automl.best_model_name else 'steelblue' for m in model_results['Model']]\n",
    "ax3.barh(model_results['Model'], model_results['Best Score'], color=colors, edgecolor='black')\n",
    "ax3.set_xlabel('CV Score')\n",
    "ax3.set_title('Model Comparison', fontweight='bold')\n",
    "for i, (model, score) in enumerate(zip(model_results['Model'], model_results['Best Score'])):\n",
    "    ax3.text(score + 0.005, i, f'{score:.3f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='part9'></a>\n",
    "# Part 9: Summary & Best Practices\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\"*70)\n",
    "print(\"AUTOMATED ML PIPELINE - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "WHAT WE LEARNED:\n",
    "================\n",
    "\n",
    "1. WHY PIPELINES?\n",
    "   - Prevent data leakage\n",
    "   - Ensure reproducibility\n",
    "   - Easy deployment (single object)\n",
    "\n",
    "2. PREPROCESSING AUTOMATION:\n",
    "   ┌─────────────────────────────────────────────┐\n",
    "   │ ColumnTransformer                           │\n",
    "   ├─────────────────────────────────────────────┤\n",
    "   │ Numeric: Imputer → Scaler                   │\n",
    "   │ Categorical: Imputer → Encoder              │\n",
    "   └─────────────────────────────────────────────┘\n",
    "\n",
    "3. FEATURE SELECTION METHODS:\n",
    "   ┌──────────────┬─────────────────┬───────────┐\n",
    "   │ Type         │ Methods         │ Speed     │\n",
    "   ├──────────────┼─────────────────┼───────────┤\n",
    "   │ Filter       │ SelectKBest     │ Fast      │\n",
    "   │ Wrapper      │ RFE, RFECV      │ Slow      │\n",
    "   │ Embedded     │ L1, Tree Imp.   │ Medium    │\n",
    "   └──────────────┴─────────────────┴───────────┘\n",
    "\n",
    "4. HYPERPARAMETER TUNING:\n",
    "   ┌──────────────────┬──────────────────────────┐\n",
    "   │ Method           │ When to Use              │\n",
    "   ├──────────────────┼──────────────────────────┤\n",
    "   │ Grid Search      │ Few parameters           │\n",
    "   │ Random Search    │ Many parameters (faster) │\n",
    "   │ Bayesian Opt.    │ Expensive evaluations    │\n",
    "   └──────────────────┴──────────────────────────┘\n",
    "\n",
    "5. CROSS-VALIDATION:\n",
    "   - StratifiedKFold for classification\n",
    "   - TimeSeriesSplit for time data\n",
    "   - 5-fold is good default\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nFINAL RESULTS:\")\n",
    "print(f\"  Best Model: {automl.best_model_name}\")\n",
    "print(f\"  CV Score: {automl.best_score:.4f}\")\n",
    "print(f\"  Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  Test ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm & Method Taxonomy\n",
    "\n",
    "### Preprocessing Methods\n",
    "\n",
    "| Method | Type | When to Use |\n",
    "|--------|------|-------------|\n",
    "| **StandardScaler** | Scaling | Normal distribution, most algorithms |\n",
    "| **MinMaxScaler** | Scaling | Neural networks, bounded range |\n",
    "| **RobustScaler** | Scaling | Data with outliers |\n",
    "| **SimpleImputer** | Imputation | Simple missing value handling |\n",
    "| **KNNImputer** | Imputation | Complex patterns in missing data |\n",
    "| **OneHotEncoder** | Encoding | Nominal categories |\n",
    "| **OrdinalEncoder** | Encoding | Ordinal categories |\n",
    "\n",
    "### Feature Selection Methods\n",
    "\n",
    "| Method | Category | Speed | Best For |\n",
    "|--------|----------|-------|----------|\n",
    "| **VarianceThreshold** | Filter | Very Fast | Remove constant features |\n",
    "| **SelectKBest** | Filter | Fast | Quick baseline |\n",
    "| **RFE** | Wrapper | Slow | Optimal subset |\n",
    "| **RFECV** | Wrapper | Very Slow | Auto-select # features |\n",
    "| **SelectFromModel** | Embedded | Medium | L1/Tree-based |\n",
    "\n",
    "### Hyperparameter Tuning Methods\n",
    "\n",
    "| Method | Combinations | Speed | Quality |\n",
    "|--------|--------------|-------|--------|\n",
    "| **GridSearchCV** | All | Slow | Guaranteed optimal |\n",
    "| **RandomizedSearchCV** | Random N | Fast | Usually good |\n",
    "| **HalvingGridSearchCV** | Progressive | Very Fast | Good |\n",
    "| **Optuna/Bayesian** | Smart | Medium | Excellent |\n",
    "\n",
    "---\n",
    "\n",
    "## Production Libraries\n",
    "\n",
    "| Library | Purpose | Complexity |\n",
    "|---------|---------|------------|\n",
    "| **sklearn Pipeline** | Manual pipelines | Low |\n",
    "| **TPOT** | Genetic algorithm AutoML | Medium |\n",
    "| **Auto-sklearn** | Meta-learning AutoML | Medium |\n",
    "| **H2O AutoML** | Enterprise AutoML | Low |\n",
    "| **Optuna** | Hyperparameter optimization | Medium |\n",
    "| **MLflow** | Experiment tracking | Medium |\n",
    "\n",
    "---\n",
    "\n",
    "## Checklist\n",
    "\n",
    "- [x] Understand why pipelines prevent data leakage\n",
    "- [x] Can build preprocessing pipelines with ColumnTransformer\n",
    "- [x] Know Filter, Wrapper, Embedded feature selection methods\n",
    "- [x] Can compare multiple models automatically\n",
    "- [x] Understand Grid Search vs Random Search trade-offs\n",
    "- [x] Know when to use which cross-validation strategy\n",
    "- [x] Can build end-to-end AutoML pipeline\n",
    "\n",
    "---\n",
    "\n",
    "**End of Automated ML Pipeline Tutorial**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}